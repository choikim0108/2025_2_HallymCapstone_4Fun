"""í•™ìƒ ìˆ˜ì— ë”°ë¥¸ ë™ì  íŒŒë¼ë¯¸í„° ì¡°ì • ëª¨ë“ˆ.

ì´ ëª¨ë“ˆì€ ì…ë ¥ëœ í•™ìƒ ìˆ˜ì— ë”°ë¼ í™”ì ë¶„ë¦¬, ìŒì„± ì¸ì‹, 
ë¶„ì„ ì•Œê³ ë¦¬ì¦˜ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
"""

import logging
from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass


@dataclass
class DiarizationParameters:
    """í™”ì ë¶„ë¦¬ íŒŒë¼ë¯¸í„°."""
    min_speakers: int
    max_speakers: int
    clustering_threshold: float
    segmentation_threshold: float
    min_segment_length: float
    max_segment_length: float


@dataclass
class RecognitionParameters:
    """ìŒì„± ì¸ì‹ íŒŒë¼ë¯¸í„°."""
    beam_size: int
    language_model_weight: float
    word_insertion_penalty: float
    chunk_length_s: int
    batch_size: int


@dataclass
class AnalysisParameters:
    """ë¶„ì„ íŒŒë¼ë¯¸í„°."""
    hesitation_threshold: float
    interaction_window: float
    participation_threshold: float
    topic_similarity_threshold: float


class AdaptiveParameterManager:
    """í•™ìƒ ìˆ˜ì— ë”°ë¥¸ ë™ì  íŒŒë¼ë¯¸í„° ê´€ë¦¬ í´ë˜ìŠ¤."""
    
    def __init__(self):
        """AdaptiveParameterManager ì´ˆê¸°í™”."""
        self.logger = logging.getLogger(__name__)
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì„¤ì •
        self._default_params = self._initialize_default_parameters()
        
        # í•™ìƒ ìˆ˜ë³„ ì¡°ì • ê·œì¹™
        self._adjustment_rules = self._initialize_adjustment_rules()
    
    def _initialize_default_parameters(self) -> Dict[str, Any]:
        """ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”."""
        return {
            'diarization': DiarizationParameters(
                min_speakers=2,
                max_speakers=6,
                clustering_threshold=0.7,
                segmentation_threshold=0.5,
                min_segment_length=0.5,
                max_segment_length=30.0
            ),
            'recognition': RecognitionParameters(
                beam_size=5,
                language_model_weight=1.0,
                word_insertion_penalty=0.0,
                chunk_length_s=30,
                batch_size=16
            ),
            'analysis': AnalysisParameters(
                hesitation_threshold=0.3,
                interaction_window=5.0,
                participation_threshold=0.1,
                topic_similarity_threshold=0.6
            )
        }
    
    def _initialize_adjustment_rules(self) -> Dict[str, Dict[str, Any]]:
        """í•™ìƒ ìˆ˜ë³„ ì¡°ì • ê·œì¹™ ì´ˆê¸°í™”."""
        return {
            'small_class': {  # 1-2ëª…
                'student_range': (1, 2),
                'diarization_adjustments': {
                    'clustering_threshold': 0.8,  # ë” ì—„ê²©í•œ í´ëŸ¬ìŠ¤í„°ë§
                    'segmentation_threshold': 0.6,
                    'min_segment_length': 1.0,  # ë” ê¸´ ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸
                },
                'recognition_adjustments': {
                    'beam_size': 3,  # ë” ì‘ì€ ë¹” í¬ê¸°
                    'chunk_length_s': 20,
                },
                'analysis_adjustments': {
                    'hesitation_threshold': 0.4,  # ë” ì—„ê²©í•œ íœ´ì§€ ê°ì§€
                    'interaction_window': 3.0,  # ë” ì§§ì€ ìƒí˜¸ì‘ìš© ìœˆë„ìš°
                    'participation_threshold': 0.15,  # ë” ë†’ì€ ì°¸ì—¬ë„ ì„ê³„ê°’
                }
            },
            'medium_class': {  # 3-4ëª…
                'student_range': (3, 4),
                'diarization_adjustments': {
                    'clustering_threshold': 0.7,  # ê¸°ë³¸ê°’ ìœ ì§€
                    'segmentation_threshold': 0.5,
                    'min_segment_length': 0.5,
                },
                'recognition_adjustments': {
                    'beam_size': 5,  # ê¸°ë³¸ê°’ ìœ ì§€
                    'chunk_length_s': 30,
                },
                'analysis_adjustments': {
                    'hesitation_threshold': 0.3,  # ê¸°ë³¸ê°’ ìœ ì§€
                    'interaction_window': 5.0,
                    'participation_threshold': 0.1,
                }
            },
            'large_class': {  # 5ëª… ì´ìƒ
                'student_range': (5, 10),
                'diarization_adjustments': {
                    'clustering_threshold': 0.6,  # ë” ê´€ëŒ€í•œ í´ëŸ¬ìŠ¤í„°ë§
                    'segmentation_threshold': 0.4,
                    'min_segment_length': 0.3,  # ë” ì§§ì€ ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸
                    'max_segment_length': 20.0,  # ë” ì§§ì€ ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸
                },
                'recognition_adjustments': {
                    'beam_size': 7,  # ë” í° ë¹” í¬ê¸°
                    'chunk_length_s': 40,  # ë” ê¸´ ì²­í¬
                    'batch_size': 8,  # ë” ì‘ì€ ë°°ì¹˜ í¬ê¸° (ë©”ëª¨ë¦¬ ì ˆì•½)
                },
                'analysis_adjustments': {
                    'hesitation_threshold': 0.25,  # ë” ê´€ëŒ€í•œ íœ´ì§€ ê°ì§€
                    'interaction_window': 7.0,  # ë” ê¸´ ìƒí˜¸ì‘ìš© ìœˆë„ìš°
                    'participation_threshold': 0.05,  # ë” ë‚®ì€ ì°¸ì—¬ë„ ì„ê³„ê°’
                    'topic_similarity_threshold': 0.5,  # ë” ê´€ëŒ€í•œ ì£¼ì œ ìœ ì‚¬ë„
                }
            }
        }
    
    def get_class_size_category(self, student_count: int) -> str:
        """í•™ìƒ ìˆ˜ì— ë”°ë¥¸ í´ë˜ìŠ¤ í¬ê¸° ì¹´í…Œê³ ë¦¬ ë°˜í™˜."""
        for category, rules in self._adjustment_rules.items():
            min_students, max_students = rules['student_range']
            if min_students <= student_count <= max_students:
                return category
        
        # ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ê²½ìš° ê°€ì¥ ê°€ê¹Œìš´ ì¹´í…Œê³ ë¦¬ ì„ íƒ
        if student_count < 1:
            return 'small_class'
        elif student_count > 10:
            return 'large_class'
        else:
            return 'medium_class'
    
    def get_adaptive_parameters(self, student_count: int) -> Dict[str, Any]:
        """í•™ìƒ ìˆ˜ì— ë”°ë¥¸ ì ì‘í˜• íŒŒë¼ë¯¸í„° ë°˜í™˜."""
        category = self.get_class_size_category(student_count)
        rules = self._adjustment_rules[category]
        
        self.logger.info(f"í•™ìƒ ìˆ˜ {student_count}ëª… â†’ í´ë˜ìŠ¤ ì¹´í…Œê³ ë¦¬: {category}")
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ë³µì‚¬
        adaptive_params = {
            'diarization': DiarizationParameters(**self._default_params['diarization'].__dict__),
            'recognition': RecognitionParameters(**self._default_params['recognition'].__dict__),
            'analysis': AnalysisParameters(**self._default_params['analysis'].__dict__)
        }
        
        # ì´ í™”ì ìˆ˜ ê³„ì‚° (í•™ìƒ + êµì‚¬)
        total_speakers = student_count + 1
        adaptive_params['diarization'].min_speakers = min(2, total_speakers)
        adaptive_params['diarization'].max_speakers = max(total_speakers + 1, 3)
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì¡°ì • ì ìš©
        for param_type, adjustments in rules.items():
            if param_type.endswith('_adjustments'):
                param_category = param_type.replace('_adjustments', '')
                if param_category in adaptive_params:
                    for param_name, value in adjustments.items():
                        if hasattr(adaptive_params[param_category], param_name):
                            setattr(adaptive_params[param_category], param_name, value)
                            self.logger.debug(f"{param_category}.{param_name} = {value}")
        
        return adaptive_params
    
    def get_diarization_config(self, student_count: int) -> Dict[str, Any]:
        """í™”ì ë¶„ë¦¬ìš© ì„¤ì • ë°˜í™˜."""
        params = self.get_adaptive_parameters(student_count)
        diarization_params = params['diarization']
        
        return {
            'num_speakers': student_count + 1,  # í•™ìƒ + êµì‚¬
            'min_speakers': diarization_params.min_speakers,
            'max_speakers': diarization_params.max_speakers,
            'clustering_threshold': diarization_params.clustering_threshold,
            'segmentation_threshold': diarization_params.segmentation_threshold,
            'min_segment_length': diarization_params.min_segment_length,
            'max_segment_length': diarization_params.max_segment_length,
        }
    
    def get_recognition_config(self, student_count: int) -> Dict[str, Any]:
        """ìŒì„± ì¸ì‹ìš© ì„¤ì • ë°˜í™˜."""
        params = self.get_adaptive_parameters(student_count)
        recognition_params = params['recognition']
        
        return {
            'beam_size': recognition_params.beam_size,
            'language_model_weight': recognition_params.language_model_weight,
            'word_insertion_penalty': recognition_params.word_insertion_penalty,
            'chunk_length_s': recognition_params.chunk_length_s,
            'batch_size': recognition_params.batch_size,
        }
    
    def get_analysis_config(self, student_count: int) -> Dict[str, Any]:
        """ë¶„ì„ìš© ì„¤ì • ë°˜í™˜."""
        params = self.get_adaptive_parameters(student_count)
        analysis_params = params['analysis']
        
        return {
            'hesitation_threshold': analysis_params.hesitation_threshold,
            'interaction_window': analysis_params.interaction_window,
            'participation_threshold': analysis_params.participation_threshold,
            'topic_similarity_threshold': analysis_params.topic_similarity_threshold,
        }
    
    def get_optimization_suggestions(self, student_count: int, 
                                   detected_speakers: int) -> Dict[str, Any]:
        """ìµœì í™” ì œì•ˆ ë°˜í™˜."""
        expected_speakers = student_count + 1
        category = self.get_class_size_category(student_count)
        
        suggestions = {
            'category': category,
            'expected_speakers': expected_speakers,
            'detected_speakers': detected_speakers,
            'speaker_count_match': detected_speakers == expected_speakers,
            'recommendations': []
        }
        
        # í™”ì ìˆ˜ ë¶ˆì¼ì¹˜ ë¶„ì„
        if detected_speakers < expected_speakers:
            diff = expected_speakers - detected_speakers
            suggestions['recommendations'].append({
                'type': 'speaker_detection',
                'issue': f'{diff}ëª…ì˜ í™”ìê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'suggestion': 'í´ëŸ¬ìŠ¤í„°ë§ ì„ê³„ê°’ì„ ë‚®ì¶”ê±°ë‚˜ ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.',
                'parameters': {
                    'clustering_threshold': max(0.5, self._default_params['diarization'].clustering_threshold - 0.1),
                    'min_segment_length': max(0.2, self._default_params['diarization'].min_segment_length - 0.2)
                }
            })
        elif detected_speakers > expected_speakers:
            diff = detected_speakers - expected_speakers
            suggestions['recommendations'].append({
                'type': 'speaker_detection',
                'issue': f'{diff}ëª…ì˜ ì¶”ê°€ í™”ìê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'suggestion': 'í´ëŸ¬ìŠ¤í„°ë§ ì„ê³„ê°’ì„ ë†’ì´ê±°ë‚˜ ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”.',
                'parameters': {
                    'clustering_threshold': min(0.9, self._default_params['diarization'].clustering_threshold + 0.1),
                    'min_segment_length': min(2.0, self._default_params['diarization'].min_segment_length + 0.3)
                }
            })
        
        # í´ë˜ìŠ¤ í¬ê¸°ë³„ ì¶”ê°€ ì œì•ˆ
        if category == 'small_class':
            suggestions['recommendations'].append({
                'type': 'small_class_optimization',
                'suggestion': 'ì†Œê·œëª¨ í´ë˜ìŠ¤ì—ì„œëŠ” ê°œë³„ í•™ìŠµìì˜ ì„¸ë°€í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.',
                'focus_areas': ['ê°œë³„ ë°œí™” íŒ¨í„´', 'ìƒì„¸í•œ ì–¸ì–´ ë¶„ì„', '1:1 ìƒí˜¸ì‘ìš© íŒ¨í„´']
            })
        elif category == 'large_class':
            suggestions['recommendations'].append({
                'type': 'large_class_optimization',
                'suggestion': 'ëŒ€ê·œëª¨ í´ë˜ìŠ¤ì—ì„œëŠ” ì „ì²´ì ì¸ ì°¸ì—¬ë„ì™€ ê·¸ë£¹ ë‹¤ì´ë‚˜ë¯¹ìŠ¤ì— ì§‘ì¤‘í•˜ì„¸ìš”.',
                'focus_areas': ['ì „ì²´ ì°¸ì—¬ë„', 'ê·¸ë£¹ ìƒí˜¸ì‘ìš©', 'ë°œí™” ì‹œê°„ ë¶„ë°°']
            })
        
        return suggestions
    
    def log_parameter_summary(self, student_count: int) -> None:
        """íŒŒë¼ë¯¸í„° ìš”ì•½ ë¡œê¹…."""
        category = self.get_class_size_category(student_count)
        params = self.get_adaptive_parameters(student_count)
        
        self.logger.info(f"ğŸ“Š ì ì‘í˜• íŒŒë¼ë¯¸í„° ìš”ì•½ (í•™ìƒ ìˆ˜: {student_count}ëª…, ì¹´í…Œê³ ë¦¬: {category})")
        self.logger.info(f"  ğŸ¯ í™”ì ë¶„ë¦¬: {params['diarization'].min_speakers}-{params['diarization'].max_speakers}ëª… ë²”ìœ„")
        self.logger.info(f"  ğŸ—£ï¸  ìŒì„± ì¸ì‹: ë¹” í¬ê¸° {params['recognition'].beam_size}, ì²­í¬ {params['recognition'].chunk_length_s}ì´ˆ")
        self.logger.info(f"  ğŸ“ˆ ë¶„ì„: íœ´ì§€ ì„ê³„ê°’ {params['analysis'].hesitation_threshold}, ìƒí˜¸ì‘ìš© ìœˆë„ìš° {params['analysis'].interaction_window}ì´ˆ") 