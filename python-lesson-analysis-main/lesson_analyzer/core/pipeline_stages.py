"""ë¶„ì„ íŒŒì´í”„ë¼ì¸ì˜ ê° ë‹¨ê³„ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆ."""

from typing import Dict, List, Optional, Tuple, Any
import logging
import os
from abc import ABC, abstractmethod

from .analysis_config import AnalysisConfig
from ..processors.audio.audio_processor import AudioProcessor
from ..processors.speech.speech_recognizer import WhisperXSpeechRecognizer
from ..analyzers.hesitation.hesitation_analyzer import HesitationAnalyzer
from ..analyzers.speaker.speaker_identifier import SpeakerIdentifier
from .student_count_input import StudentCountManager
from .adaptive_parameters import AdaptiveParameterManager
from .auth_manager import AuthManager

logger = logging.getLogger(__name__)


class PipelineStage(ABC):
    """íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ì˜ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤."""
    
    def __init__(self, config: AnalysisConfig):
        self.config = config
    
    @abstractmethod
    def execute(self, *args, **kwargs) -> Any:
        """ë‹¨ê³„ ì‹¤í–‰."""
        pass


class AudioExtractionStage(PipelineStage):
    """ì˜¤ë””ì˜¤ ì¶”ì¶œ ë‹¨ê³„."""
    
    def __init__(self, config: AnalysisConfig):
        super().__init__(config)
        self.audio_processor = AudioProcessor()
    
    def execute(self, video_path: str) -> str:
        """ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ."""
        logger.info("ğŸ“¹ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
        return self.audio_processor.extract_audio(video_path)


class WhisperXStage(PipelineStage):
    """WhisperX í†µí•© ìŒì„± ì¸ì‹ ë° í™”ì ë¶„ë¦¬ ë‹¨ê³„."""
    
    def __init__(self, config: AnalysisConfig):
        super().__init__(config)
        hf_token = os.environ.get('HUGGINGFACE_TOKEN') or os.environ.get('HF_TOKEN')
        if not hf_token:
            try:
                hf_token = AuthManager().get_token()
            except Exception:
                hf_token = None
        self.recognizer = WhisperXSpeechRecognizer(
            model_name=config.whisperx_model,
            device="cuda" if config.use_gpu else "cpu",
            enable_diarization=config.enable_diarization,
            hf_token=hf_token
        )
        self.student_count_manager = StudentCountManager(
            config_dir=f"{config.output_dir}/config",
            analysis_config=config
        )
        self.adaptive_param_manager = AdaptiveParameterManager()
    
    def execute(self, audio_path: str) -> Tuple[Dict, Dict[str, List[Dict]]]:
        """WhisperXë¥¼ ì‚¬ìš©í•œ í†µí•© ìŒì„± ì¸ì‹ ë° í™”ì ë¶„ë¦¬ ìˆ˜í–‰."""
        logger.info("ğŸ¯ WhisperX í†µí•© ì²˜ë¦¬ ì¤‘ (ìŒì„± ì¸ì‹ + í™”ì ë¶„ë¦¬)...")
        
        # í•™ìƒ ìˆ˜ ê²°ì •
        if self.config.num_speakers is None:
            student_count = self.student_count_manager.get_student_count(
                interactive=self.config.interactive_input,
                session_id=self.config.session_id
            )
            
            # ì ì‘í˜• íŒŒë¼ë¯¸í„° ì ìš©
            diarization_config = self.adaptive_param_manager.get_diarization_config(student_count)
            total_speakers = diarization_config['num_speakers']
            
            logger.info(f"ğŸ“ í•™ìƒ ìˆ˜ {student_count}ëª… â†’ ì´ ì˜ˆìƒ í™”ì ìˆ˜: {total_speakers}ëª…")
        else:
            total_speakers = self.config.num_speakers
            student_count = self.config.num_speakers - 1
            logger.info(f"ğŸ¯ ì‚¬ìš©ì ì§€ì • í™”ì ìˆ˜: {total_speakers}ëª…")

        # WhisperX í†µí•© ì²˜ë¦¬ ìˆ˜í–‰
        result = self.recognizer.transcribe_with_diarization(
            audio_path,
            min_speakers=self.config.min_speakers or 1,
            max_speakers=self.config.max_speakers or total_speakers
        )
        
        # ê²°ê³¼ ë¶„ë¦¬
        diarization_result = {
            'segments': result.segments,
            'speakers': list(set(seg['speaker'] for seg in result.segments if 'speaker' in seg)),
            'audio_duration': result.audio_duration
        }
        
        # í™”ìë³„ ì „ì‚¬ ê²°ê³¼ êµ¬ì„±
        transcripts_by_speaker = {}
        for segment in result.segments:
            speaker_id = segment.get('speaker', 'SPEAKER_00')
            if speaker_id not in transcripts_by_speaker:
                transcripts_by_speaker[speaker_id] = []
            
            transcripts_by_speaker[speaker_id].append({
                'start': segment['start'],
                'end': segment['end'],
                'text': segment['text'],
                'confidence': segment.get('confidence', 0.9)
            })
        
        # í™”ì ìˆ˜ ê²€ì¦
        if self.config.num_speakers is None and 'speakers' in diarization_result:
            detected_count = len(diarization_result['speakers'])
            is_consistent, validation_msg = self.student_count_manager.validate_detected_speakers(
                student_count, detected_count
            )
            logger.info(validation_msg)
            
            if not is_consistent:
                logger.warning("âš ï¸  ì˜ˆìƒ í™”ì ìˆ˜ì™€ ê°ì§€ëœ í™”ì ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            else:
                logger.info("âœ… í™”ì ìˆ˜ ì¼ì¹˜: ì ì‘í˜• íŒŒë¼ë¯¸í„°ê°€ íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™í–ˆìŠµë‹ˆë‹¤.")
        
        logger.info(f"âœ… WhisperX ì²˜ë¦¬ ì™„ë£Œ: {len(diarization_result['speakers'])}ëª… í™”ì, {len(result.segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        
        return diarization_result, transcripts_by_speaker


# SpeechRecognitionStageëŠ” WhisperXStageë¡œ í†µí•©ë˜ì–´ ì œê±°ë¨


class SpeakerIdentificationStage(PipelineStage):
    """í™”ì ì‹ë³„ ë‹¨ê³„."""
    
    def __init__(self, config: AnalysisConfig):
        super().__init__(config)
    
    def execute(self, audio_path: str, diarization_result: Dict, 
                transcription_result: Dict[str, List[Dict]]) -> Dict:
        """í™”ì ì‹ë³„ ìˆ˜í–‰ - ëª¨ë“  í™”ìë¥¼ person_N í˜•íƒœë¡œ ëª…ëª…."""
        logger.info("ğŸ‘¤ í™”ì ëª…ëª… ì¤‘...")
        
        # í•„í„°ë§ëœ í™”ìë“¤ì„ person_1, person_2 í˜•íƒœë¡œ ëª…ëª…
        filtered_speaker_ids = list(transcription_result.keys())
        logger.info(f"ğŸ¯ ê°ì§€ëœ í™”ì ìˆ˜: {len(filtered_speaker_ids)}ëª…")
        
        # í™”ì IDë¥¼ ì •ë ¬í•˜ì—¬ ì¼ê´€ëœ ìˆœì„œë¡œ person_N í• ë‹¹
        filtered_speaker_ids.sort()
        
        # speaker_roles ë§¤í•‘ ìƒì„± (SPEAKER_X -> person_N)
        speaker_roles = {}
        for i, original_speaker_id in enumerate(filtered_speaker_ids, 1):
            new_speaker_id = f"person_{i}"
            speaker_roles[original_speaker_id] = new_speaker_id
        
        # transcription_resultì˜ í‚¤ë¥¼ ìƒˆë¡œìš´ person_N í˜•íƒœë¡œ ë³€ê²½
        updated_transcription_result = {}
        for original_id, transcripts in transcription_result.items():
            new_id = speaker_roles[original_id]
            updated_transcription_result[new_id] = transcripts
            
            # ê° ì „ì‚¬ ê²°ê³¼ì˜ speaker í•„ë“œë„ ì—…ë°ì´íŠ¸
            for transcript in transcripts:
                transcript['speaker'] = new_id
        
        # ê²°ê³¼ êµ¬ì„±
        result = {
            'speaker_roles': speaker_roles,  # SPEAKER_X -> person_N ë§¤í•‘
            'speaker_mapping': {v: k for k, v in speaker_roles.items()},  # person_N -> SPEAKER_X ì—­ë§¤í•‘
            'updated_transcription': updated_transcription_result,  # person_N í‚¤ë¥¼ ê°€ì§„ ì „ì‚¬ ê²°ê³¼
            'person_ids': list(speaker_roles.values())  # [person_1, person_2, ...]
        }
        
        logger.info(f"âœ… í™”ì ëª…ëª… ì™„ë£Œ: {list(speaker_roles.values())}")
        
        return result


class HesitationAnalysisStage(PipelineStage):
    """ë°œì„± íœ´ì§€ ë¶„ì„ ë‹¨ê³„."""
    
    def __init__(self, config: AnalysisConfig):
        super().__init__(config)
        self.hesitation_analyzer = HesitationAnalyzer()
    
    def execute(self, audio_path: str, diarization_result: Dict, 
                transcripts_by_speaker: Dict[str, List[Dict]],
                speaker_identification_result: Dict) -> Dict[str, Any]:
        """ë°œì„± íœ´ì§€ ë¶„ì„ ìˆ˜í–‰."""
        logger.info("â¸ï¸ ë°œì„± íœ´ì§€ ë¶„ì„ ì¤‘...")
        
        # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
        logger.info(f"ì „ì‚¬ ê²°ê³¼ í‚¤ë“¤: {list(transcripts_by_speaker.keys())}")
        logger.info(f"í™”ì ì‹ë³„ ê²°ê³¼ í‚¤ë“¤: {list(speaker_identification_result.keys())}")
        
        # ì—…ë°ì´íŠ¸ëœ ì „ì‚¬ ê²°ê³¼ ì‚¬ìš© (person_N í˜•íƒœ)
        updated_transcription = speaker_identification_result.get('updated_transcription', {})
        speaker_mapping = speaker_identification_result.get('speaker_mapping', {})  # person_N -> SPEAKER_X
        
        logger.info(f"ì—…ë°ì´íŠ¸ëœ ì „ì‚¬ ê²°ê³¼ í‚¤ë“¤: {list(updated_transcription.keys())}")
        logger.info(f"í™”ì ë§¤í•‘: {speaker_mapping}")
        
        hesitation_results = {}
        
        # diarization_resultì—ì„œ segments ì¶”ì¶œ
        segments = diarization_result.get('segments', [])
        
        for person_id, transcripts in updated_transcription.items():
            if transcripts:  # ì „ì‚¬ ê²°ê³¼ê°€ ìˆëŠ” í™”ìë§Œ ë¶„ì„
                logger.info(f"â¸ï¸ {person_id} ë°œì„± íœ´ì§€ ë¶„ì„ ì¤‘...")
                
                # person_idì— í•´ë‹¹í•˜ëŠ” ì›ë³¸ speaker_id ì°¾ê¸°
                original_speaker_id = speaker_mapping.get(person_id)
                if not original_speaker_id:
                    logger.warning(f"âš ï¸ {person_id}ì— í•´ë‹¹í•˜ëŠ” ì›ë³¸ í™”ì IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # í•´ë‹¹ í™”ìì˜ diarization ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
                speaker_segments = [seg for seg in segments if seg['speaker'] == original_speaker_id]
                
                # í•´ë‹¹ í™”ìì˜ ì „ì‚¬ ê²°ê³¼ë¥¼ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                # HesitationAnalyzerê°€ ì›ë³¸ speaker_idë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ ë§¤í•‘ ì‚¬ìš©
                speaker_transcripts = []
                for transcript in transcripts:
                    speaker_transcripts.append({
                        'speaker': original_speaker_id,  # ì›ë³¸ speaker_id ì‚¬ìš© (HesitationAnalyzer í˜¸í™˜ì„±)
                        'start': transcript['start'],
                        'end': transcript['end'],
                        'text': transcript['text']
                    })
                
                # ë°œì„± íœ´ì§€ ë¶„ì„ ìˆ˜í–‰
                speaker_result = self.hesitation_analyzer.analyze_speaker_hesitation(
                    audio_path, speaker_segments, speaker_transcripts
                )
                hesitation_results[person_id] = speaker_result
        
        return hesitation_results


class LanguageAnalysisStage(PipelineStage):
    """ì–¸ì–´ ë¶„ì„ ë‹¨ê³„."""
    
    def __init__(self, config: AnalysisConfig):
        super().__init__(config)
        # ê¸°ë³¸ ì–¸ì–´ë¥¼ ì˜ì–´ë¡œ ì„¤ì • (í–¥í›„ configì—ì„œ ì–¸ì–´ ì„¤ì • ì¶”ê°€ ê°€ëŠ¥)
        language = getattr(config, 'language', 'en')
        
        # LanguageAnalysisServiceë§Œ ìƒì„±í•˜ì—¬ ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€
        from ..services.language_analysis_service import LanguageAnalysisService
        self.language_analysis_service = LanguageAnalysisService(language=language)
    
    def execute(self, transcripts_by_speaker: Dict[str, List[Dict]],
                speaker_identification_result: Dict) -> Dict[str, Any]:
        """ì–¸ì–´ ë¶„ì„ ìˆ˜í–‰."""
        logger.info("ğŸ“ ì–¸ì–´ ë¶„ì„ ì¤‘...")
        
        # ì—…ë°ì´íŠ¸ëœ ì „ì‚¬ ê²°ê³¼ ì‚¬ìš© (person_N í˜•íƒœ)
        updated_transcription = speaker_identification_result.get('updated_transcription', {})
        
        grammar_results = {}
        vocabulary_results = {}
        topic_results = {}
        
        for person_id, transcripts in updated_transcription.items():
            if transcripts:  # ì „ì‚¬ ê²°ê³¼ê°€ ìˆëŠ” í™”ìë§Œ ë¶„ì„
                logger.info(f"ğŸ“ {person_id} ì–¸ì–´ ë¶„ì„ ì¤‘...")
                
                # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
                full_text = " ".join([
                    segment['text'] for segment in transcripts
                ])
                
                # ê°œë³„ ì „ì‚¬ ì„¸ê·¸ë¨¼íŠ¸ ëª©ë¡ (ì‹œê°„ ì •ë³´ í¬í•¨)
                transcript_segments = [
                    {
                        'text': segment['text'],
                        'start': segment['start'],
                        'end': segment['end']
                    }
                    for segment in transcripts
                ]
                
                # ë¬¸ë²• ë¶„ì„ (LanguageAnalysisService ì‚¬ìš©)
                grammar_results[person_id] = self.language_analysis_service._analyze_grammar(full_text)
                
                # ì–´íœ˜ ë¶„ì„ (LanguageAnalysisService ì‚¬ìš©)
                vocabulary_results[person_id] = self.language_analysis_service._analyze_vocabulary(full_text)
                
                # ìƒˆë¡œìš´ ì£¼ì œ ì¹œë°€ë„ ë¶„ì„ (ë°œí™”ëŸ‰, ì°¸ì—¬ë„, ë¶ˆí™•ì‹¤ì„± ì¢…í•©)
                topic_results[person_id] = self._analyze_participation_familiarity(
                    person_id, transcript_segments, full_text
                )
        
        # configì— ê³µìœ ëœ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì €ì¥ (ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€)
        if hasattr(self.config, '__dict__'):
            self.config._shared_language_analysis_service = self.language_analysis_service
        
        # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜í•˜ì—¬ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë„ í¬í•¨
        return {
            'grammar_analysis': grammar_results,
            'vocabulary_analysis': vocabulary_results,
            'topic_analysis': topic_results,
            'language_analysis_service': self.language_analysis_service  # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ í¬í•¨
        }
    
    def _analyze_participation_familiarity(self, person_id: str, transcript_segments: List[Dict], 
                                         full_text: str) -> Dict:
        """
        ìƒˆë¡œìš´ ì£¼ì œ ì¹œë°€ë„ ë¶„ì„: ë°œí™”ëŸ‰, ì°¸ì—¬ë„, ë¶ˆí™•ì‹¤ì„± í‘œí˜„ ì¢…í•© ë¶„ì„.
        
        Args:
            person_id: í™”ì ID (person_N)
            transcript_segments: ì‹œê°„ ì •ë³´ê°€ í¬í•¨ëœ ì „ì‚¬ ì„¸ê·¸ë¨¼íŠ¸
            full_text: ì „ì²´ ë°œí™” í…ìŠ¤íŠ¸
            
        Returns:
            ì¢…í•© ì£¼ì œ ì¹œë°€ë„ ë¶„ì„ ê²°ê³¼
        """
        # ê° ë¶„ì„ ìˆ˜í–‰
        speech_analysis = self._analyze_speech_volume(transcript_segments, full_text)
        uncertainty_analysis = self._analyze_uncertainty_patterns(full_text)
        interaction_analysis = self._analyze_interaction_patterns(full_text)
        keyword_analysis = self._analyze_basic_keywords(full_text)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        scores = self._calculate_comprehensive_scores(
            speech_analysis, uncertainty_analysis, interaction_analysis
        )
        
        # ê²°ê³¼ êµ¬ì„±
        return self._build_familiarity_result(
            scores, speech_analysis, uncertainty_analysis, 
            interaction_analysis, keyword_analysis
        )
    
    def _analyze_speech_volume(self, transcript_segments: List[Dict], full_text: str) -> Dict:
        """ë°œí™”ëŸ‰ ë° ì°¸ì—¬ë„ ë¶„ì„."""
        total_words = len(full_text.split())
        total_duration = sum(seg['end'] - seg['start'] for seg in transcript_segments)
        segment_count = len(transcript_segments)
        
        # í‰ê·  ë°œí™” ê¸¸ì´ ë° ë¹ˆë„
        avg_words_per_segment = total_words / max(segment_count, 1)
        speaking_frequency = (segment_count / max(total_duration / 60, 0.1)) if total_duration > 0 else 0
        
        # ë°œí™”ëŸ‰ ì ìˆ˜ ê³„ì‚°
        speech_volume_score = min(total_words / 100, 1.0)
        participation_score = min((avg_words_per_segment * speaking_frequency) / 20, 1.0)
        
        return {
            'total_words': total_words,
            'total_duration': round(total_duration, 2),
            'segment_count': segment_count,
            'avg_words_per_segment': round(avg_words_per_segment, 1),
            'speaking_frequency': round(speaking_frequency, 2),
            'speech_volume_score': round(speech_volume_score, 3),
            'participation_score': round(participation_score, 3)
        }
    
    def _analyze_uncertainty_patterns(self, full_text: str) -> Dict:
        """ë¶ˆí™•ì‹¤ì„± í‘œí˜„ ë¶„ì„."""
        import re
        
        uncertainty_patterns = [
            r'\bI don\'?t know\b', r'\bI\'?m not sure\b', r'\bmaybe\b',
            r'\bprobably\b', r'\bI think\b', r'\bcould be\b',
            r'\bperhaps\b', r'\bmight be\b', r'\bI guess\b',
            r'\bwell\b', r'\bum\b', r'\buh\b', r'\ber\b'
        ]
        
        uncertainty_count = sum(
            len(re.findall(pattern, full_text, re.IGNORECASE)) 
            for pattern in uncertainty_patterns
        )
        
        total_words = len(full_text.split())
        uncertainty_ratio = uncertainty_count / max(total_words, 1)
        confidence_score = max(0, 1 - uncertainty_ratio * 10)
        
        # ê³µí†µ ë¶ˆí™•ì‹¤ì„± í‘œí˜„ ì¶”ì¶œ
        common_uncertainties = [
            match.group() for pattern in uncertainty_patterns[:5]
            for match in re.finditer(pattern, full_text, re.IGNORECASE)
        ][:10]
        
        return {
            'uncertainty_count': uncertainty_count,
            'uncertainty_ratio': round(uncertainty_ratio, 3),
            'confidence_score': round(confidence_score, 3),
            'common_uncertainties': common_uncertainties
        }
    
    def _analyze_interaction_patterns(self, full_text: str) -> Dict:
        """ì§ˆë¬¸ ë° ê¸ì •ì  ì°¸ì—¬ í‘œí˜„ ë¶„ì„."""
        import re
        
        question_patterns = [
            r'\?', r'\bwhat\b', r'\bhow\b', r'\bwhy\b',
            r'\bwhen\b', r'\bwhere\b', r'\bwho\b'
        ]
        
        positive_patterns = [
            r'\byes\b', r'\bokay\b', r'\bgood\b', r'\bgreat\b',
            r'\bI see\b', r'\bI understand\b', r'\bthat\'?s right\b', r'\bexactly\b'
        ]
        
        question_count = sum(
            len(re.findall(pattern, full_text, re.IGNORECASE)) 
            for pattern in question_patterns
        )
        
        positive_count = sum(
            len(re.findall(pattern, full_text, re.IGNORECASE)) 
            for pattern in positive_patterns
        )
        
        total_words = len(full_text.split())
        question_ratio = question_count / max(total_words, 1)
        positive_ratio = positive_count / max(total_words, 1)
        engagement_score = min((question_ratio + positive_ratio) * 10, 1.0)
        
        return {
            'question_count': question_count,
            'question_ratio': round(question_ratio, 3),
            'positive_count': positive_count,
            'positive_ratio': round(positive_ratio, 3),
            'engagement_score': round(engagement_score, 3)
        }
    
    def _analyze_basic_keywords(self, full_text: str) -> Dict:
        """ê¸°ë³¸ í‚¤ì›Œë“œ ë¶„ì„ (ì°¨íŠ¸ í˜¸í™˜ì„±ìš©)."""
        basic_keywords = ['what', 'how', 'when', 'where', 'why', 'because', 'since', 'so', 'then', 'after']
        matched_keywords = sum(1 for keyword in basic_keywords if keyword in full_text.lower())
        keyword_match_ratio = matched_keywords / len(basic_keywords) if basic_keywords else 0.0
        
        student_keywords = [word for word in full_text.lower().split() if len(word) > 3][:10]
        
        return {
            'keyword_match_ratio': round(keyword_match_ratio, 3),
            'topic_keywords': basic_keywords[:5],
            'student_keywords': student_keywords
        }
    
    def _calculate_comprehensive_scores(self, speech_analysis: Dict, 
                                      uncertainty_analysis: Dict, 
                                      interaction_analysis: Dict) -> Dict:
        """ì¢…í•© ì ìˆ˜ ê³„ì‚°."""
        # ìµœì¢… ì£¼ì œ ì¹œë°€ë„ ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
        final_familiarity_score = (
            speech_analysis['speech_volume_score'] * 0.3 +      # ë°œí™”ëŸ‰ 30%
            speech_analysis['participation_score'] * 0.25 +     # ì°¸ì—¬ë„ 25%
            uncertainty_analysis['confidence_score'] * 0.25 +   # í™•ì‹¤ì„± 25%
            interaction_analysis['engagement_score'] * 0.2      # ì ê·¹ì„± 20%
        )
        
        # ì˜ë¯¸ ìœ ì‚¬ë„ ê·¼ì‚¬ì¹˜
        semantic_similarity = (
            uncertainty_analysis['confidence_score'] * 0.6 + 
            interaction_analysis['engagement_score'] * 0.4
        )
        
        return {
            'final_familiarity_score': round(final_familiarity_score, 3),
            'semantic_similarity': round(semantic_similarity, 3)
        }
    
    def _build_familiarity_result(self, scores: Dict, speech_analysis: Dict, 
                                uncertainty_analysis: Dict, interaction_analysis: Dict, 
                                keyword_analysis: Dict) -> Dict:
        """ìµœì¢… ë¶„ì„ ê²°ê³¼ êµ¬ì„±."""
        final_score = scores['final_familiarity_score']
        
        return {
            # í˜¸í™˜ì„±ì„ ìœ„í•œ í•„ë“œë“¤ (ì°¨íŠ¸ ìƒì„±ì— í•„ìš”)
            'familiarity_score': final_score,
            'keyword_match_ratio': keyword_analysis['keyword_match_ratio'],
            'semantic_similarity': scores['semantic_similarity'],
            'topic_engagement': interaction_analysis['engagement_score'],
            'off_topic_ratio': round(max(0, uncertainty_analysis['uncertainty_ratio'] * 2), 3),
            'topic_keywords': keyword_analysis['topic_keywords'],
            'student_keywords': keyword_analysis['student_keywords'],
            'improvement_suggestions': self._generate_topic_improvement_suggestions(
                final_score, uncertainty_analysis['uncertainty_ratio'], 
                interaction_analysis['engagement_score']
            ),
            
            # ê¸°ì¡´ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë“¤
            'overall_familiarity_score': final_score,
            'speech_analysis': speech_analysis,
            'participation_analysis': {
                'participation_score': speech_analysis['participation_score'],
                'engagement_score': interaction_analysis['engagement_score']
            },
            'uncertainty_analysis': uncertainty_analysis,
            'interaction_patterns': interaction_analysis,
            'interpretation': self._interpret_familiarity_score(final_score)
        }
    
    def _interpret_familiarity_score(self, score: float) -> str:
        """ì£¼ì œ ì¹œë°€ë„ ì ìˆ˜ë¥¼ í•´ì„í•©ë‹ˆë‹¤."""
        if score >= 0.8:
            return "ë§¤ìš° ë†’ìŒ - ì£¼ì œì— ëŒ€í•´ ìì‹ ê° ìˆê²Œ ëŒ€í™”í•˜ë©° ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬"
        elif score >= 0.6:
            return "ë†’ìŒ - ì£¼ì œë¥¼ ì˜ ì´í•´í•˜ê³  í™œë°œí•˜ê²Œ ëŒ€í™” ì°¸ì—¬"
        elif score >= 0.4:
            return "ë³´í†µ - ê¸°ë³¸ì ì¸ ì°¸ì—¬ëŠ” í•˜ì§€ë§Œ ì•½ê°„ì˜ ì–´ë ¤ì›€ í‘œì¶œ"
        elif score >= 0.2:
            return "ë‚®ìŒ - ì£¼ì œì— ëŒ€í•œ ì–´ë ¤ì›€ì„ ëŠë¼ë©° ì†Œê·¹ì  ì°¸ì—¬"
        else:
            return "ë§¤ìš° ë‚®ìŒ - ì£¼ì œì— ëŒ€í•œ ì´í•´ ë¶€ì¡± ë° ë§¤ìš° ì†Œê·¹ì  ì°¸ì—¬"
    
    def _generate_topic_improvement_suggestions(self, familiarity_score: float, 
                                              uncertainty_ratio: float, 
                                              engagement_score: float) -> List[str]:
        """ì£¼ì œ ì¹œë°€ë„ ê°œì„  ì œì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤."""
        suggestions = []
        
        if familiarity_score >= 0.7:
            suggestions.append("ì£¼ì œì— ëŒ€í•œ ì´í•´ë„ê°€ ìš°ìˆ˜í•©ë‹ˆë‹¤. í˜„ì¬ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ì„¸ìš”.")
            suggestions.append("ë” ë³µì¡í•œ ì£¼ì œë‚˜ ì„¸ë¶€ ì‚¬í•­ì— ëŒ€í•´ì„œë„ ë„ì „í•´ë³´ì„¸ìš”.")
        elif familiarity_score >= 0.5:
            suggestions.append("ì£¼ì œì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì´í•´ê°€ ìˆìŠµë‹ˆë‹¤.")
            if uncertainty_ratio > 0.1:
                suggestions.append("ë¶ˆí™•ì‹¤í•œ í‘œí˜„ì„ ì¤„ì´ê³  ë” ìì‹ ê° ìˆê²Œ ë§í•´ë³´ì„¸ìš”.")
            if engagement_score < 0.5:
                suggestions.append("ë” ì ê·¹ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³  ëŒ€í™”ì— ì°¸ì—¬í•´ë³´ì„¸ìš”.")
        else:
            suggestions.append("ì£¼ì œì— ëŒ€í•´ ë” ë§ì€ ì¤€ë¹„ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            suggestions.append("ê´€ë ¨ ì–´íœ˜ë¥¼ ë¯¸ë¦¬ í•™ìŠµí•˜ê³  ì—°ìŠµí•´ë³´ì„¸ìš”.")
            if uncertainty_ratio > 0.15:
                suggestions.append("'I don't know'ë³´ë‹¤ëŠ” ë¶€ë¶„ì ìœ¼ë¡œë¼ë„ ì•Œê³  ìˆëŠ” ê²ƒì„ í‘œí˜„í•´ë³´ì„¸ìš”.")
        
        return suggestions


class InteractionAnalysisStage(PipelineStage):
    """ìƒí˜¸ì‘ìš© ë¶„ì„ ë‹¨ê³„."""
    
    def __init__(self, config: AnalysisConfig):
        super().__init__(config)
    
    def execute(self, diarization_result: Dict, speaker_identification_result: Dict) -> Dict:
        """ìƒí˜¸ì‘ìš© ë¶„ì„ ìˆ˜í–‰."""
        logger.info("ğŸ¤ ìƒí˜¸ì‘ìš© ë¶„ì„ ì¤‘...")
        
        # diarization_resultì—ì„œ segments ì¶”ì¶œ
        segments = diarization_result.get('segments', [])
        speaker_roles = speaker_identification_result.get('speaker_roles', {})  # SPEAKER_X -> person_N
        speaker_mapping = speaker_identification_result.get('speaker_mapping', {})  # person_N -> SPEAKER_X
        person_ids = speaker_identification_result.get('person_ids', [])
        
        # ìœ íš¨í•œ í™”ì ID ëª©ë¡ (ì›ë³¸ SPEAKER_X í˜•íƒœ)
        valid_speaker_ids = set(speaker_roles.keys())
        
        # í™”ìë³„ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ê·¸ë£¹í™” (ì›ë³¸ SPEAKER_Xë¡œ)
        speaker_segments = {}
        for segment in segments:
            speaker_id = segment['speaker']
            # ìœ íš¨í•œ í™”ìë§Œ í¬í•¨
            if speaker_id in valid_speaker_ids:
                if speaker_id not in speaker_segments:
                    speaker_segments[speaker_id] = []
                speaker_segments[speaker_id].append(segment)
        
        # person_N í˜•íƒœë¡œ ê²°ê³¼ êµ¬ì„±
        person_segments = {}
        for original_speaker_id, segs in speaker_segments.items():
            person_id = speaker_roles.get(original_speaker_id)
            if person_id:
                person_segments[person_id] = segs
        
        interaction_metrics = {
            'total_participants': len(person_segments),
            'participant_distribution': {},
            'session_summary': {
                'total_segments': len(segments),
                'total_duration': sum(seg['end'] - seg['start'] for seg in segments),
                'participants': person_ids
            }
        }
        
        # ê° ì°¸ì—¬ìë³„ ë°œí™” í†µê³„ ê³„ì‚°
        total_session_duration = interaction_metrics['session_summary']['total_duration']
        
        for person_id, person_segs in person_segments.items():
            total_duration = sum(seg['end'] - seg['start'] for seg in person_segs)
            segment_count = len(person_segs)
            
            # ë°œí™” ì‹œê°„ ë¹„ìœ¨ ê³„ì‚°
            duration_percentage = (total_duration / max(total_session_duration, 1)) * 100
            
            # í‰ê·  ë°œí™” ê¸¸ì´
            avg_segment_duration = total_duration / max(segment_count, 1)
            
            # ë°œí™” ë¹ˆë„ (ë¶„ë‹¹ ë°œí™” íšŸìˆ˜)
            speaking_frequency = (segment_count / max(total_session_duration / 60, 0.1)) if total_session_duration > 0 else 0
            
            interaction_metrics['participant_distribution'][person_id] = {
                'total_duration': round(total_duration, 2),
                'duration_percentage': round(duration_percentage, 1),
                'segment_count': segment_count,
                'avg_segment_duration': round(avg_segment_duration, 2),
                'speaking_frequency': round(speaking_frequency, 2),
                'participation_level': self._categorize_participation_level(duration_percentage)
            }
        
        return interaction_metrics
    
    def _categorize_participation_level(self, duration_percentage: float) -> str:
        """ë°œí™” ì‹œê°„ ë¹„ìœ¨ì— ë”°ë¥¸ ì°¸ì—¬ë„ ìˆ˜ì¤€ ë¶„ë¥˜."""
        if duration_percentage >= 40:
            return "ë§¤ìš° í™œë°œ"
        elif duration_percentage >= 25:
            return "í™œë°œ"
        elif duration_percentage >= 15:
            return "ë³´í†µ"
        elif duration_percentage >= 5:
            return "ì†Œê·¹ì "
        else:
            return "ë§¤ìš° ì†Œê·¹ì "


class ReportGenerationStage(PipelineStage):
    """ë¦¬í¬íŠ¸ ìƒì„± ë‹¨ê³„ - ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±."""
    
    def __init__(self, config: AnalysisConfig):
        super().__init__(config)
        # ReportGeneratorService ì´ˆê¸°í™”ëŠ” ì‹¤í–‰ ì‹œì ì—ì„œ ìˆ˜í–‰
        self.report_service = None
    
    def execute(self, audio_extraction_result: Dict, diarization_result: Dict, 
                recognition_result: Dict, speaker_identification_result: Dict,
                hesitation_result: Dict, language_result: Dict, 
                interaction_result: Dict) -> Dict:
        """ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±."""
        logger.info("ğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        try:
            # ReportGeneratorService lazy ì´ˆê¸°í™”
            if self.report_service is None:
                from ..services.report_generator_service import ReportGeneratorService
                
                # ê³µìœ ëœ LanguageAnalysisService ê°€ì ¸ì˜¤ê¸°
                shared_language_service = getattr(self.config, '_shared_language_analysis_service', None)
                
                self.report_service = ReportGeneratorService(
                    self.config, 
                    language_analysis_service=shared_language_service
                )
            
            # ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©
            consolidated_results = {
                'audio_extraction': audio_extraction_result,
                'diarization': diarization_result,
                'recognition': recognition_result,
                'speaker_identification': speaker_identification_result,
                'hesitation_analysis': hesitation_result,
                'language_analysis': language_result,
                'interaction_analysis': interaction_result
            }
            
            # ë¦¬í¬íŠ¸ ìƒì„± (ì˜¬ë°”ë¥¸ ë©”ì„œë“œ í˜¸ì¶œ)
            report_result = self.report_service.generate_markdown_report(
                consolidated_results
            )
            
            logger.info("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
            return report_result
            
        except Exception as e:
            logger.error(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': str(e),
                'reports': {},
                'summary': {}
            }