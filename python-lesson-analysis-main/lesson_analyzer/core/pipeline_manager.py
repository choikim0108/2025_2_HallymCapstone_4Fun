"""ë¶„ì„ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ ëª¨ë“ˆ."""

import logging
from typing import Dict, Any

from .analysis_config import AnalysisConfig
from .pipeline_stages import (
    AudioExtractionStage, WhisperXStage,
    SpeakerIdentificationStage, HesitationAnalysisStage, LanguageAnalysisStage,
    InteractionAnalysisStage, ReportGenerationStage
)
from .speaker_name_manager import SpeakerNameManager
from .dependency_manager import DependencyManager, PipelineStage, PipelineTask, ExecutionMode
from .performance_monitor import PerformanceMonitor

logger = logging.getLogger(__name__)


class PipelineManager:
    """ë¶„ì„ íŒŒì´í”„ë¼ì¸ì˜ ì „ì²´ íë¦„ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤."""

    def __init__(self, config: AnalysisConfig):
        """
        PipelineManager ì´ˆê¸°í™”.

        Args:
            config: ë¶„ì„ ì„¤ì • ê°ì²´
        """
        self.config = config
        
        # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë“¤ ì´ˆê¸°í™”
        self.audio_extraction = AudioExtractionStage(config)
        self.whisperx_stage = WhisperXStage(config)
        self.speaker_identification = SpeakerIdentificationStage(config)
        self.hesitation_analysis = HesitationAnalysisStage(config)
        self.language_analysis = LanguageAnalysisStage(config)
        self.interaction_analysis = InteractionAnalysisStage(config)
        self.report_generation = ReportGenerationStage(config)
        
        # í™”ì ì´ë¦„ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.speaker_name_manager = SpeakerNameManager(
            config_dir=f"{config.output_dir}/config",
            analysis_config=config
        )
        
        # ê´€ë¦¬ìë“¤ ì´ˆê¸°í™”
        self.dependency_manager = DependencyManager(output_dir=config.output_dir)
        
        # PerformanceMonitorëŠ” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ìƒì„±
        self.performance_monitor = None
        if getattr(config, 'enable_performance_monitoring', False):
            self.performance_monitor = PerformanceMonitor(
                output_dir=f"{config.output_dir}/performance_logs"
            )

    def execute_pipeline(self, video_path: str) -> Dict[str, Any]:
        """
        ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            video_path: ì˜ìƒ íŒŒì¼ ê²½ë¡œ

        Returns:
            ì „ì²´ ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info("ğŸš€ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # 1. ì˜¤ë””ì˜¤ ì¶”ì¶œ
        audio_path = self.audio_extraction.execute(video_path)
        
        # ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        results = self.execute_audio_pipeline(audio_path)
        
        # ì˜¤ë””ì˜¤ ê²½ë¡œ ì¶”ê°€
        results['audio_extraction'] = {'audio_path': audio_path}
        
        logger.info("âœ… ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        return results

    def execute_audio_pipeline(self, audio_path: str) -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤ (ì˜¤ë””ì˜¤ ì¶”ì¶œ ë‹¨ê³„ ì œì™¸).

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (í™”ì ì´ë¦„ ë§¤í•‘ í¬í•¨)
        """
        logger.info("ğŸš€ ì˜¤ë””ì˜¤ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # 2. WhisperX í†µí•© ì²˜ë¦¬ (ìŒì„± ì¸ì‹ + í™”ì ë¶„ë¦¬)
        if self.performance_monitor:
            self.performance_monitor.start_stage(PipelineStage.SPEECH_RECOGNITION)
        diarization_result, transcripts_by_speaker = self.whisperx_stage.execute(audio_path)
        if self.performance_monitor:
            self.performance_monitor.end_stage(PipelineStage.SPEECH_RECOGNITION)
        
        # WhisperX ê²°ê³¼ì—ì„œ í™”ì ì •ë³´ ì¶”ì¶œ (ì´ë¯¸ diarization_resultì— í¬í•¨ë¨)
        
        # 4. í™”ì ì‹ë³„ (person_N í˜•íƒœë¡œ ëª…ëª…)
        if self.performance_monitor:
            self.performance_monitor.start_stage(PipelineStage.SPEAKER_IDENTIFICATION)
        speaker_identification_result = self.speaker_identification.execute(
            audio_path, diarization_result, transcripts_by_speaker
        )
        if self.performance_monitor:
            self.performance_monitor.end_stage(PipelineStage.SPEAKER_IDENTIFICATION)
        
        # 5. ë°œì„± íœ´ì§€ ë¶„ì„
        if self.performance_monitor:
            self.performance_monitor.start_stage(PipelineStage.HESITATION_ANALYSIS)
        hesitation_analysis_result = self.hesitation_analysis.execute(
            audio_path, diarization_result, transcripts_by_speaker, speaker_identification_result
        )
        if self.performance_monitor:
            self.performance_monitor.end_stage(PipelineStage.HESITATION_ANALYSIS)
        
        # 6. ì–¸ì–´ ë¶„ì„ (ìƒˆë¡œìš´ ì£¼ì œ ì¹œë°€ë„ ë¶„ì„ í¬í•¨)
        if self.performance_monitor:
            self.performance_monitor.start_stage(PipelineStage.LANGUAGE_ANALYSIS)
        language_analysis_result = self.language_analysis.execute(
            transcripts_by_speaker, speaker_identification_result
        )
        if self.performance_monitor:
            self.performance_monitor.end_stage(PipelineStage.LANGUAGE_ANALYSIS)
        
        # 7. ìƒí˜¸ì‘ìš© ë¶„ì„
        if self.performance_monitor:
            self.performance_monitor.start_stage(PipelineStage.INTERACTION_ANALYSIS)
        interaction_analysis_result = self.interaction_analysis.execute(
            diarization_result, speaker_identification_result
        )
        if self.performance_monitor:
            self.performance_monitor.end_stage(PipelineStage.INTERACTION_ANALYSIS)
        
        # 8. í™”ì ì´ë¦„ ì…ë ¥ ë‹¨ê³„
        logger.info("ğŸ“ í™”ì ì´ë¦„ ì…ë ¥ ë‹¨ê³„...")
        updated_transcription = speaker_identification_result.get('updated_transcription', {})
        
        # í™”ì ì´ë¦„ ë§¤í•‘ ìƒì„±
        if self.config.interactive_input:
            # ëŒ€í™”í˜• ëª¨ë“œ: ì‚¬ìš©ìë¡œë¶€í„° ì´ë¦„ ì…ë ¥ ë°›ê¸°
            speaker_names = self.speaker_name_manager.get_speaker_names_interactive(
                updated_transcription, session_id=self.config.session_id
            )
        else:
            # ë¹„ëŒ€í™”í˜• ëª¨ë“œ: ê¸°ë³¸ ì´ë¦„ ì‚¬ìš©
            speaker_names = self.speaker_name_manager.get_speaker_names_non_interactive(
                updated_transcription
            )
        
        # Step 1: í™”ì ì´ë¦„ ì…ë ¥ ê²°ê³¼ ë¡œê¹…
        logger.debug(f"ğŸ” [Step 1] í™”ì ì´ë¦„ ìƒì„± ê²°ê³¼: {speaker_names}")
        logger.debug(f"ğŸ” [Step 1] updated_transcription í‚¤: {list(updated_transcription.keys())}")
        
        # ì´ë¦„ ìœ íš¨ì„± ê²€ì¦
        is_valid, errors = self.speaker_name_manager.validate_speaker_names(speaker_names)
        if not is_valid:
            logger.warning(f"í™”ì ì´ë¦„ ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨: {errors}")
            # ì˜¤ë¥˜ê°€ ìˆì–´ë„ ê³„ì† ì§„í–‰í•˜ë˜ ê¸°ë³¸ ì´ë¦„ ì‚¬ìš©
            speaker_names = self.speaker_name_manager.get_speaker_names_non_interactive(
                updated_transcription
            )
        
        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
        analysis_results = {
            'speaker_diarization': diarization_result,
            'speech_recognition': transcripts_by_speaker,
            'speaker_identification': speaker_identification_result,
            'hesitation_analysis': hesitation_analysis_result,
            'language_analysis': [
                language_analysis_result.get('grammar_analysis', {}),
                language_analysis_result.get('vocabulary_analysis', {}),
                language_analysis_result.get('topic_analysis', {})
            ],  # ê¸°ì¡´ íŠœí”Œ í˜•ì‹ ìœ ì§€
            'interaction_analysis': interaction_analysis_result,
            'speaker_names': speaker_names,  # í™”ì ì´ë¦„ ë§¤í•‘ ì¶”ê°€
            'final_speaker_mapping': self._create_final_speaker_mapping(
                speaker_identification_result, speaker_names
            ),
            'language_analysis_service': language_analysis_result.get('language_analysis_service')  # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì „ë‹¬
        }
        
        # Step 3: analysis_results ë°ì´í„° ì „ë‹¬ í™•ì¸ ë¡œê¹…
        logger.debug(f"ğŸ” [Step 3] analysis_resultsì— í¬í•¨ëœ í™”ì ë°ì´í„°:")
        logger.debug(f"ğŸ” [Step 3] - speaker_names: {analysis_results.get('speaker_names')}")
        logger.debug(f"ğŸ” [Step 3] - final_speaker_mapping: {analysis_results.get('final_speaker_mapping')}")
        
        # 8. ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„ (ëª¨ë“  ë¶„ì„ ê²°ê³¼ í†µí•©)
        logger.info("ğŸ“‹ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        if self.performance_monitor:
            self.performance_monitor.start_stage(PipelineStage.REPORT_GENERATION)
        report_result = self.report_generation.execute(
            {'audio_path': audio_path},  # audio_extraction_result
            diarization_result,
            transcripts_by_speaker,
            speaker_identification_result,
            hesitation_analysis_result,
            language_analysis_result,
            interaction_analysis_result
        )
        if self.performance_monitor:
            self.performance_monitor.end_stage(PipelineStage.REPORT_GENERATION)
        
        # ë³´ê³ ì„œ ìƒì„± ê²°ê³¼ë¥¼ analysis_resultsì— ì¶”ê°€
        analysis_results['reports'] = report_result
        
        # ì„±ëŠ¥ ë¡œê·¸ ì •ë³´ ì¶œë ¥
        self._log_performance_summary()
        
        logger.info("âœ… ì˜¤ë””ì˜¤ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ (ë³´ê³ ì„œ ìƒì„± í¬í•¨)")
        return analysis_results
    
    def _create_final_speaker_mapping(self, speaker_identification_result: Dict, 
                                    speaker_names: Dict[str, str]) -> Dict[str, str]:
        """
        ìµœì¢… í™”ì ë§¤í•‘ì„ ìƒì„±í•©ë‹ˆë‹¤ (person_N -> ì‚¬ìš©ì ì…ë ¥ ì´ë¦„).
        
        Args:
            speaker_identification_result: í™”ì ì‹ë³„ ê²°ê³¼
            speaker_names: í™”ì ì´ë¦„ ë§¤í•‘
            
        Returns:
            ìµœì¢… í™”ì ë§¤í•‘ (person_N -> ì´ë¦„)
        """
        # Step 2: final_speaker_mapping ìƒì„± ì‹œì‘ ë¡œê¹…
        logger.debug(f"ğŸ” [Step 2] final_speaker_mapping ìƒì„± ì‹œì‘")
        logger.debug(f"ğŸ” [Step 2] speaker_identification_result í‚¤: {list(speaker_identification_result.keys())}")
        logger.debug(f"ğŸ” [Step 2] ì…ë ¥ë°›ì€ speaker_names: {speaker_names}")
        
        final_mapping = {}
        person_ids = speaker_identification_result.get('person_ids', [])
        logger.debug(f"ğŸ” [Step 2] person_ids: {person_ids}")
        
        for person_id in person_ids:
            if person_id in speaker_names:
                final_mapping[person_id] = speaker_names[person_id]
            else:
                # ì´ë¦„ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì´ë¦„ ì‚¬ìš©
                person_num = person_id.split('_')[1] if '_' in person_id else '1'
                final_mapping[person_id] = f"ì°¸ì—¬ì{person_num}"
        
        # Step 2: final_speaker_mapping ìƒì„± ì™„ë£Œ ë¡œê¹…
        logger.debug(f"ğŸ” [Step 2] final_speaker_mapping ìƒì„± ì™„ë£Œ: {final_mapping}")
        
        return final_mapping

    def _log_performance_summary(self) -> None:
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
        try:
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ì„±ëŠ¥ ê´€ë ¨ ì¶œë ¥
            if self.performance_monitor:
                # ì„±ëŠ¥ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥
                if hasattr(self.performance_monitor, 'log_file'):
                    logger.info(f"ğŸ“Š ì„±ëŠ¥ ë¡œê·¸ íŒŒì¼: {self.performance_monitor.log_file}")
                
                # ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ì¶œë ¥ (ê°„ë‹¨ ë²„ì „)
                dashboard = self.performance_monitor.generate_performance_dashboard()
                total_warnings = dashboard['overview']['total_warnings']
                avg_duration = dashboard['overview']['avg_pipeline_duration']
                
                if total_warnings > 0:
                    logger.warning(f"âš ï¸  ì„±ëŠ¥ ê²½ê³  {total_warnings}íšŒ ë°œìƒ. í‰ê·  íŒŒì´í”„ë¼ì¸ ì‹œê°„: {avg_duration:.2f}ì´ˆ")
            else:
                logger.info(f"âœ… ëª¨ë“  ë‹¨ê³„ ì •ìƒ ì™„ë£Œ. í‰ê·  íŒŒì´í”„ë¼ì¸ ì‹œê°„: {avg_duration:.2f}ì´ˆ")
                
        except Exception as e:
            logger.warning(f"ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥ ì‹¤íŒ¨: {e}")

    def set_speaker_roles(self, speaker_roles: Dict[str, str]) -> None:
        """
        í™”ì ì—­í• ì„ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        
        Args:
            speaker_roles: í™”ì IDì™€ ì—­í• ì˜ ë§¤í•‘
        """
        # ì„¤ì •ì„ configì— ì €ì¥
        self.config.speaker_roles = speaker_roles
        
        # SpeakerIdentifierì— ì„¤ì • ì ìš©
        if hasattr(self.speaker_identification.speaker_identifier, 'set_speaker_roles'):
            self.speaker_identification.speaker_identifier.set_speaker_roles(speaker_roles)
        else:
            logger.warning("SpeakerIdentifierê°€ set_speaker_roles ë©”ì„œë“œë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")