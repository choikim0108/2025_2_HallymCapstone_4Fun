"""ë¶„ì„ ê²°ê³¼ë“¤ì„ ìˆ˜ì§‘í•˜ê³  í†µí•©í•˜ëŠ” ëª¨ë“ˆ."""

from typing import Dict, List, Optional, Tuple, Any, Union
import logging
import json
import os
from datetime import datetime
from dataclasses import dataclass, asdict

from ..generators.report_generator import ReportGenerator

logger = logging.getLogger(__name__)


@dataclass
class AnalysisMetadata:
    """ë¶„ì„ ë©”íƒ€ë°ì´í„°."""
    timestamp: str
    video_path: str
    audio_path: str
    num_speakers: int
    session_id: Optional[str] = None
    processing_time: Optional[float] = None
    parameters: Optional[Dict[str, Any]] = None


@dataclass
class ConsolidatedResults:
    """í†µí•©ëœ ë¶„ì„ ê²°ê³¼."""
    metadata: AnalysisMetadata
    speaker_diarization: Dict[str, Any]
    speech_recognition: Dict[str, List[Dict]]
    speaker_identification: Dict[str, Any]
    hesitation_analysis: Dict[str, Any]
    language_analysis: Tuple[Dict, Dict, Dict]
    interaction_analysis: Dict[str, Any]
    performance_metrics: Optional[Dict[str, Any]] = None


class ResultAggregator:
    """ë¶„ì„ ê²°ê³¼ë“¤ì„ ìˆ˜ì§‘í•˜ê³  í†µí•©í•˜ëŠ” í´ë˜ìŠ¤."""
    
    def __init__(self, output_dir: str, config=None):
        """
        ResultAggregator ì´ˆê¸°í™”.
        
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            config: AnalysisConfig ê°ì²´ (ì„ íƒì )
        """
        self.output_dir = output_dir
        self.results_dir = os.path.join(output_dir, "results")
        
        # results ë””ë ‰í† ë¦¬ëŠ” save_dataê°€ Trueì¼ ë•Œë§Œ ìƒì„±
        should_create_results_dir = False
        if config and hasattr(config, 'save_data'):
            should_create_results_dir = config.save_data
        elif not config:
            should_create_results_dir = False
            
        if should_create_results_dir:
            os.makedirs(self.results_dir, exist_ok=True)
        
        # ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™”
        self.report_generator = ReportGenerator(output_dir)
        
    def aggregate_results(self, 
                         video_path: str,
                         audio_path: str,
                         num_speakers: int,
                         analysis_results: Dict[str, Any],
                         session_id: Optional[str] = None,
                         processing_time: Optional[float] = None,
                         parameters: Optional[Dict[str, Any]] = None) -> ConsolidatedResults:
        """
        ë¶„ì„ ê²°ê³¼ë“¤ì„ í†µí•©í•©ë‹ˆë‹¤.
        
        Args:
            video_path: ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            audio_path: ì¶”ì¶œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            num_speakers: í™”ì ìˆ˜
            analysis_results: ê° ë‹¨ê³„ë³„ ë¶„ì„ ê²°ê³¼
            session_id: ì„¸ì…˜ ID
            processing_time: ì´ ì²˜ë¦¬ ì‹œê°„
            parameters: ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„°ë“¤
            
        Returns:
            í†µí•©ëœ ë¶„ì„ ê²°ê³¼
        """
        logger.info("ë¶„ì„ ê²°ê³¼ í†µí•© ì‹œì‘")
        
        # ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = AnalysisMetadata(
            timestamp=datetime.now().isoformat(),
            video_path=video_path,
            audio_path=audio_path,
            num_speakers=num_speakers,
            session_id=session_id,
            processing_time=processing_time,
            parameters=parameters
        )
        
        # ì–¸ì–´ ë¶„ì„ ê²°ê³¼ ë¶„ë¦¬
        language_analysis_result = analysis_results.get('language_analysis_result', ({}, {}, {}))
        if isinstance(language_analysis_result, tuple) and len(language_analysis_result) == 3:
            language_analysis = language_analysis_result
        else:
            # ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ë¶„ë¦¬ ì‹œë„
            if isinstance(language_analysis_result, dict):
                language_analysis = (
                    language_analysis_result.get('grammar_analysis', {}),
                    language_analysis_result.get('vocabulary_analysis', {}),
                    language_analysis_result.get('topic_analysis', {})
                )
            else:
                language_analysis = ({}, {}, {})
                logger.warning("ì–¸ì–´ ë¶„ì„ ê²°ê³¼ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤.")
        
        # í†µí•© ê²°ê³¼ ìƒì„±
        consolidated = ConsolidatedResults(
            metadata=metadata,
            speaker_diarization=analysis_results.get('speaker_diarization_result', {}),
            speech_recognition=analysis_results.get('speech_recognition_result', {}),
            speaker_identification=analysis_results.get('speaker_identification_result', {}),
            hesitation_analysis=analysis_results.get('hesitation_analysis_result', {}),
            language_analysis=language_analysis,
            interaction_analysis=analysis_results.get('interaction_analysis_result', {}),
            performance_metrics=analysis_results.get('performance_metrics', {})
        )
        
        logger.info("ë¶„ì„ ê²°ê³¼ í†µí•© ì™„ë£Œ")
        return consolidated
        
    def save_results(self, results: ConsolidatedResults, 
                    filename: Optional[str] = None) -> str:
        """
        í†µí•©ëœ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            results: í†µí•©ëœ ë¶„ì„ ê²°ê³¼
            filename: ì €ì¥í•  íŒŒì¼ëª… (Noneì´ë©´ ìë™ ìƒì„±)
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        if filename is None:
            timestamp = results.metadata.timestamp.replace(':', '-').replace('.', '-')
            filename = f"analysis_results_{timestamp}.json"
            
        filepath = os.path.join(self.results_dir, filename)
        
        try:
            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            results_dict = self._to_serializable_dict(results)
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results_dict, f, ensure_ascii=False, indent=2)
                
            logger.info(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
            
    def load_results(self, filepath: str) -> ConsolidatedResults:
        """
        ì €ì¥ëœ ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            filepath: ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ë¡œë“œëœ ë¶„ì„ ê²°ê³¼
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                results_dict = json.load(f)
                
            # ë”•ì…”ë„ˆë¦¬ë¥¼ ConsolidatedResultsë¡œ ë³€í™˜
            results = self._from_dict(results_dict)
            
            logger.info(f"ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: {filepath}")
            return results
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
            
    def get_summary(self, results: ConsolidatedResults) -> Dict[str, Any]:
        """
        ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            results: í†µí•©ëœ ë¶„ì„ ê²°ê³¼
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ìš”ì•½
        """
        summary = {
            "metadata": {
                "timestamp": results.metadata.timestamp,
                "num_speakers": results.metadata.num_speakers,
                "processing_time": results.metadata.processing_time,
                "session_id": results.metadata.session_id
            },
            "speaker_stats": self._get_speaker_stats(results),
            "speech_stats": self._get_speech_stats(results),
            "language_stats": self._get_language_stats(results),
            "interaction_stats": self._get_interaction_stats(results)
        }
        
        return summary
        
    def _get_speaker_stats(self, results: ConsolidatedResults) -> Dict[str, Any]:
        """í™”ì ê´€ë ¨ í†µê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        stats = {}
        
        # í™”ì ë¶„ë¦¬ í†µê³„
        if results.speaker_diarization:
            speakers = results.speaker_diarization.get('speakers', [])
            stats['detected_speakers'] = len(speakers)
            stats['total_segments'] = len(results.speaker_diarization.get('segments', []))
            
        # í™”ì ì‹ë³„ í†µê³„
        if results.speaker_identification:
            identified_speakers = results.speaker_identification.get('speaker_mapping', {})
            stats['identified_speakers'] = len(identified_speakers)
            
        return stats
        
    def _get_speech_stats(self, results: ConsolidatedResults) -> Dict[str, Any]:
        """ìŒì„± ì¸ì‹ ê´€ë ¨ í†µê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        stats = {}
        
        if results.speech_recognition:
            total_transcripts = 0
            total_confidence = 0
            confidence_count = 0
            
            for speaker, transcripts in results.speech_recognition.items():
                total_transcripts += len(transcripts)
                for transcript in transcripts:
                    if 'confidence' in transcript:
                        total_confidence += transcript['confidence']
                        confidence_count += 1
                        
            stats['total_transcripts'] = total_transcripts
            stats['avg_confidence'] = total_confidence / confidence_count if confidence_count > 0 else 0
            
        return stats
        
    def _get_language_stats(self, results: ConsolidatedResults) -> Dict[str, Any]:
        """ì–¸ì–´ ë¶„ì„ ê´€ë ¨ í†µê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        stats = {}
        
        if results.language_analysis and len(results.language_analysis) == 3:
            grammar_analysis, vocabulary_analysis, topic_analysis = results.language_analysis
            
            # ë¬¸ë²• ë¶„ì„ í†µê³„
            if grammar_analysis:
                stats['grammar_errors'] = len(grammar_analysis.get('errors', []))
                stats['grammar_score'] = grammar_analysis.get('overall_score', 0)
                
            # ì–´íœ˜ ë¶„ì„ í†µê³„
            if vocabulary_analysis:
                stats['vocabulary_diversity'] = vocabulary_analysis.get('diversity_score', 0)
                stats['unique_words'] = vocabulary_analysis.get('unique_word_count', 0)
                
            # ì£¼ì œ ë¶„ì„ í†µê³„
            if topic_analysis:
                stats['topic_relevance'] = topic_analysis.get('relevance_score', 0)
                stats['detected_topics'] = len(topic_analysis.get('topics', []))
                
        return stats
        
    def _get_interaction_stats(self, results: ConsolidatedResults) -> Dict[str, Any]:
        """ìƒí˜¸ì‘ìš© ë¶„ì„ ê´€ë ¨ í†µê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        stats = {}
        
        if results.interaction_analysis:
            stats['turn_taking_score'] = results.interaction_analysis.get('turn_taking_score', 0)
            stats['participation_balance'] = results.interaction_analysis.get('participation_balance', 0)
            stats['total_interactions'] = results.interaction_analysis.get('total_interactions', 0)
            
        return stats
        
    def _to_serializable_dict(self, results: ConsolidatedResults) -> Dict[str, Any]:
        """ConsolidatedResultsë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        results_dict = asdict(results)
        
        # ì–¸ì–´ ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        if isinstance(results_dict['language_analysis'], tuple):
            grammar, vocabulary, topic = results_dict['language_analysis']
            results_dict['language_analysis'] = {
                'grammar_analysis': grammar,
                'vocabulary_analysis': vocabulary,
                'topic_analysis': topic
            }
            
        return results_dict
        
    def _from_dict(self, results_dict: Dict[str, Any]) -> ConsolidatedResults:
        """ë”•ì…”ë„ˆë¦¬ë¥¼ ConsolidatedResultsë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        # ë©”íƒ€ë°ì´í„° ë³€í™˜
        metadata = AnalysisMetadata(**results_dict['metadata'])
        
        # ì–¸ì–´ ë¶„ì„ ê²°ê³¼ë¥¼ íŠœí”Œë¡œ ë³€í™˜
        language_analysis = results_dict['language_analysis']
        if isinstance(language_analysis, dict):
            language_analysis = (
                language_analysis.get('grammar_analysis', {}),
                language_analysis.get('vocabulary_analysis', {}),
                language_analysis.get('topic_analysis', {})
            )
        elif not isinstance(language_analysis, tuple):
            language_analysis = ({}, {}, {})
            
        return ConsolidatedResults(
            metadata=metadata,
            speaker_diarization=results_dict['speaker_diarization'],
            speech_recognition=results_dict['speech_recognition'],
            speaker_identification=results_dict['speaker_identification'],
            hesitation_analysis=results_dict['hesitation_analysis'],
            language_analysis=language_analysis,
            interaction_analysis=results_dict['interaction_analysis'],
            performance_metrics=results_dict.get('performance_metrics')
        )
        
    def list_saved_results(self) -> List[Dict[str, str]]:
        """
        ì €ì¥ëœ ê²°ê³¼ íŒŒì¼ë“¤ì˜ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            íŒŒì¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (íŒŒì¼ëª…, ê²½ë¡œ, ìˆ˜ì • ì‹œê°„)
        """
        results = []
        
        try:
            for filename in os.listdir(self.results_dir):
                if filename.endswith('.json'):
                    filepath = os.path.join(self.results_dir, filename)
                    mtime = os.path.getmtime(filepath)
                    
                    results.append({
                        'filename': filename,
                        'filepath': filepath,
                        'modified_time': datetime.fromtimestamp(mtime).isoformat()
                    })
                    
            # ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœì‹  ìˆœ)
            results.sort(key=lambda x: x['modified_time'], reverse=True)
            
        except Exception as e:
            logger.error(f"ê²°ê³¼ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
        return results
        
    def generate_final_report(self, video_path: str, final_results: Dict[str, Any], 
                             save_data: bool = True) -> str:
        """
        ìµœì¢… ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            video_path: ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            final_results: ì „ì²´ ë¶„ì„ ê²°ê³¼
            save_data: ì¤‘ê°„ ë°ì´í„° ì €ì¥ ì—¬ë¶€
            
        Returns:
            ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ
        """
        logger.info("ğŸ“Š ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì‹œì‘")
        
        try:
            # 1. ë¶„ì„ ê²°ê³¼ ì •ë¦¬ ë° êµ¬ì¡°í™”
            structured_data = self._structure_analysis_data(final_results)
            
            # 2. ì¤‘ê°„ ë°ì´í„° ì €ì¥ (ì˜µì…˜)
            if save_data:
                self._save_intermediate_data(video_path, final_results)
            
            # 3. ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
            report_path = self.report_generator.generate_markdown_report(structured_data)
            
            logger.info(f"âœ… ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_path}")
            return report_path
            
        except Exception as e:
            logger.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise
    
    def _structure_analysis_data(self, final_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê³ ì„œ ìƒì„±ì— ì í•©í•œ êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            final_results: ì›ë³¸ ë¶„ì„ ê²°ê³¼
            
        Returns:
            êµ¬ì¡°í™”ëœ ë¶„ì„ ë°ì´í„°
        """
        structured_data = {
            'timestamp': datetime.now().isoformat(),
            'metadata': {
                'analysis_complete': True,
                'total_stages': len(final_results)
            }
        }
        
        # í™”ì ë¶„ë¦¬ ê²°ê³¼ ì²˜ë¦¬
        if 'speaker_diarization' in final_results:
            structured_data['speaker_diarization'] = final_results['speaker_diarization']
        
        # ìŒì„± ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬
        if 'speech_recognition' in final_results:
            structured_data['speech_recognition'] = final_results['speech_recognition']
        
        # í™”ì ì‹ë³„ ê²°ê³¼ ì²˜ë¦¬
        if 'speaker_identification' in final_results:
            structured_data['speaker_identification'] = final_results['speaker_identification']
        
        # í™”ì ì´ë¦„ ë§¤í•‘ ì²˜ë¦¬
        if 'speaker_names' in final_results:
            structured_data['speaker_names'] = final_results['speaker_names']
        
        # ìµœì¢… í™”ì ë§¤í•‘ ì²˜ë¦¬
        if 'final_speaker_mapping' in final_results:
            structured_data['final_speaker_mapping'] = final_results['final_speaker_mapping']
        
        # ë°œì„± íœ´ì§€ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
        if 'hesitation_analysis' in final_results:
            structured_data['hesitation_analysis'] = final_results['hesitation_analysis']
        
        # ì–¸ì–´ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
        if 'language_analysis' in final_results:
            structured_data['language_analysis'] = final_results['language_analysis']
        
        # ìƒí˜¸ì‘ìš© ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
        if 'interaction_analysis' in final_results:
            structured_data['interaction_analysis'] = final_results['interaction_analysis']
        
        # ì˜¤ë””ì˜¤ ì¶”ì¶œ ê²°ê³¼ ì²˜ë¦¬
        if 'audio_extraction' in final_results:
            structured_data['audio_extraction'] = final_results['audio_extraction']
        
        # ì–¸ì–´ ë¶„ì„ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì „ë‹¬ (ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€)
        if 'language_analysis_service' in final_results:
            structured_data['language_analysis_service'] = final_results['language_analysis_service']
            logger.debug("ê¸°ì¡´ LanguageAnalysisService ì¸ìŠ¤í„´ìŠ¤ë¥¼ structured_dataì— í¬í•¨")
        
        return structured_data
    
    def _save_intermediate_data(self, video_path: str, final_results: Dict[str, Any]) -> None:
        """
        ì¤‘ê°„ ë¶„ì„ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            video_path: ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            final_results: ë¶„ì„ ê²°ê³¼
        """
        try:
            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            video_basename = os.path.splitext(os.path.basename(video_path))[0]
            filename = f"analysis_data_{timestamp}.json"  # ì¼ê´€ì„±ì„ ìœ„í•´ íŒŒì¼ëª… ë‹¨ìˆœí™”
            filepath = os.path.join(self.results_dir, filename)
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(final_results, f, ensure_ascii=False, indent=2, default=str)
                
            logger.info(f"ğŸ“ ì¤‘ê°„ ë¶„ì„ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì¤‘ê°„ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}") 