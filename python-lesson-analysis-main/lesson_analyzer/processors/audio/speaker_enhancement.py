"""í™”ì ë¶„ë¦¬ ê°œì„  ëª¨ë“ˆ - ì„ë² ë”© ê¸°ë°˜ ì¬í´ëŸ¬ìŠ¤í„°ë§."""

import os
import json
import logging
import numpy as np
import librosa
import soundfile as sf
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path

from .embeddings import SpeakerEmbeddingExtractor
from ...analyzers.speaker.speaker_clustering import SpeakerClusterer
from .validator import DiarizationValidator
from .types import DiarizationResult

logger = logging.getLogger(__name__)


class SpeakerDiarizationEnhancer:
    """í™”ì ë¶„ë¦¬ ê²°ê³¼ë¥¼ ì„ë² ë”© ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ê°œì„ í•˜ëŠ” í´ë˜ìŠ¤."""
    
    def __init__(self, embedding_model: str = "speechbrain/spkrec-ecapa-voxceleb", 
                 clustering_method: str = "agglomerative", use_gpu: bool = True):
        """
        SpeakerDiarizationEnhancer ì´ˆê¸°í™”.
        
        Args:
            embedding_model: í™”ì ì„ë² ë”© ëª¨ë¸
            clustering_method: í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²• ("agglomerative", "spectral")
            use_gpu: GPU ì‚¬ìš© ì—¬ë¶€
        """
        self.embedding_extractor = SpeakerEmbeddingExtractor(
            embedding_model=embedding_model,
            use_gpu=use_gpu
        )
        self.clusterer = SpeakerClusterer(clustering_method=clustering_method)
        self.validator = DiarizationValidator()
        
        # ì„ì‹œ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ì§€ì—° ìƒì„±)
        self.temp_dir = Path("temp_audio_segments")
        self._temp_dir_created = False
    
    def __del__(self):
        """ê°ì²´ ì†Œë©¸ ì‹œ ì„ì‹œ íŒŒì¼ ì •ë¦¬."""
        try:
            self._cleanup_temp_files()
        except:
            pass  # ì†Œë©¸ìì—ì„œëŠ” ì˜ˆì™¸ë¥¼ ë¬´ì‹œ
        
    def enhance_diarization_with_embeddings(self, audio_path: str, 
                                          original_diarization: DiarizationResult,
                                          expected_speakers: Optional[int] = None,
                                          min_segment_duration: float = 1.0) -> Tuple[DiarizationResult, Dict]:
        """
        ì„ë² ë”© ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ í™”ì ë¶„ë¦¬ ê²°ê³¼ ê°œì„ .
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            original_diarization: ì›ë³¸ í™”ì ë¶„ë¦¬ ê²°ê³¼
            expected_speakers: ì˜ˆìƒ í™”ì ìˆ˜ (Noneì´ë©´ ìë™ ê²°ì •)
            min_segment_duration: ì„ë² ë”© ì¶”ì¶œì— ì‚¬ìš©í•  ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´(ì´ˆ)
            
        Returns:
            (ê°œì„ ëœ í™”ì ë¶„ë¦¬ ê²°ê³¼, ê°œì„  ì •ë³´ ë”•ì…”ë„ˆë¦¬)
        """
        logger.info("ğŸ”„ ì„ë² ë”© ê¸°ë°˜ í™”ì ë¶„ë¦¬ ê°œì„  ì‹œì‘")
        
        try:
            # 1. ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
            logger.info("ğŸ“‚ í™”ìë³„ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ ì¤‘...")
            speaker_segments = self._extract_audio_segments(
                audio_path, original_diarization, min_segment_duration
            )
            
            if len(speaker_segments) < 2:
                logger.warning("ì„ë² ë”© ì¶”ì¶œì— ì¶©ë¶„í•œ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return original_diarization, {"enhancement_applied": False, "reason": "insufficient_segments"}
            
            # 2. í™”ìë³„ ì„ë² ë”© ì¶”ì¶œ
            logger.info("ğŸ§  í™”ìë³„ ì„ë² ë”© ì¶”ì¶œ ì¤‘...")
            speaker_embeddings = self._extract_speaker_embeddings(speaker_segments)
            
            if len(speaker_embeddings) < 2:
                logger.warning("ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨. ì›ë³¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return original_diarization, {"enhancement_applied": False, "reason": "embedding_extraction_failed"}
            
            # 3. ì„ë² ë”© ê¸°ë°˜ ì¬í´ëŸ¬ìŠ¤í„°ë§
            logger.info("ğŸ¯ ì„ë² ë”© ê¸°ë°˜ ì¬í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰ ì¤‘...")
            new_clusters = self.clusterer.cluster_speakers_by_embeddings(
                speaker_embeddings, expected_speakers
            )
            
            # 4. í™”ì ID ë§¤í•‘ ìƒì„±
            logger.info("ğŸ”„ í™”ì ID ë§¤í•‘ ìƒì„± ì¤‘...")
            speaker_mapping = self._create_speaker_mapping(original_diarization, new_clusters)
            
            # 5. ê°œì„ ëœ í™”ì ë¶„ë¦¬ ê²°ê³¼ ìƒì„±
            enhanced_diarization = self._apply_speaker_mapping(original_diarization, speaker_mapping)
            
            # 6. ê°œì„  íš¨ê³¼ í‰ê°€
            improvement_metrics = self._evaluate_improvement(
                original_diarization, enhanced_diarization, speaker_embeddings, new_clusters
            )
            
            logger.info(f"âœ… í™”ì ë¶„ë¦¬ ê°œì„  ì™„ë£Œ: {improvement_metrics['improvement_summary']}")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            self._cleanup_temp_files()
            
            return enhanced_diarization, {
                "enhancement_applied": True,
                "original_speakers": len(set(seg["speaker"] for seg in original_diarization["segments"])),
                "enhanced_speakers": len(new_clusters),
                "speaker_mapping": speaker_mapping,
                "improvement_metrics": improvement_metrics
            }
            
        except Exception as e:
            logger.error(f"í™”ì ë¶„ë¦¬ ê°œì„  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self._cleanup_temp_files()
            return original_diarization, {"enhancement_applied": False, "error": str(e)}
    
    def _extract_audio_segments(self, audio_path: str, diarization: DiarizationResult, 
                               min_duration: float = 1.0) -> Dict[str, List[str]]:
        """
        í™”ìë³„ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ íŒŒì¼ë¡œ ì¶”ì¶œ.
        
        Args:
            audio_path: ì›ë³¸ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            diarization: í™”ì ë¶„ë¦¬ ê²°ê³¼
            min_duration: ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´
            
        Returns:
            í™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ ê²½ë¡œ ëª©ë¡
        """
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (í•„ìš”í•  ë•Œë§Œ)
        if not self._temp_dir_created:
            self.temp_dir.mkdir(exist_ok=True)
            self._temp_dir_created = True
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio, sr = librosa.load(audio_path, sr=None)
        
        speaker_segments = {}
        
        for i, segment in enumerate(diarization["segments"]):
            speaker = segment["speaker"]
            start_time = segment["start"]
            end_time = segment["end"]
            duration = end_time - start_time
            
            # ê°œì„ ëœ ìµœì†Œ ê¸¸ì´ í•„í„°ë§
            if duration < min_duration:
                logger.debug(f"ì„¸ê·¸ë¨¼íŠ¸ {i} ê±´ë„ˆë›°ê¸°: ë„ˆë¬´ ì§§ìŒ ({duration:.2f}ì´ˆ < {min_duration}ì´ˆ)")
                continue
            
            # ì˜¤ë””ì˜¤ í’ˆì§ˆ í™•ì¸ (ë¬´ìŒ êµ¬ê°„ í•„í„°ë§)
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            audio_segment = audio[start_sample:end_sample]
            
            # ë¬´ìŒ êµ¬ê°„ í™•ì¸ (RMSê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì œì™¸)
            rms = np.sqrt(np.mean(audio_segment**2))
            if rms < 0.001:  # ë¬´ìŒ ì„ê³„ê°’
                logger.debug(f"ì„¸ê·¸ë¨¼íŠ¸ {i} ê±´ë„ˆë›°ê¸°: ë¬´ìŒ êµ¬ê°„ (RMS: {rms:.6f})")
                continue
            
            # íŒŒì¼ë¡œ ì €ì¥
            segment_filename = f"segment_{speaker}_{i}_{start_time:.2f}_{end_time:.2f}.wav"
            segment_path = self.temp_dir / segment_filename
            
            sf.write(segment_path, audio_segment, sr)
            
            if speaker not in speaker_segments:
                speaker_segments[speaker] = []
            speaker_segments[speaker].append(str(segment_path))
        
        logger.info(f"ì¶”ì¶œëœ ì„¸ê·¸ë¨¼íŠ¸: {sum(len(segs) for segs in speaker_segments.values())}ê°œ "
                   f"({len(speaker_segments)}ëª… í™”ì)")
        
        return speaker_segments
    
    def _extract_speaker_embeddings(self, speaker_segments: Dict[str, List[str]]) -> Dict[str, np.ndarray]:
        """
        í™”ìë³„ ì„ë² ë”© ì¶”ì¶œ.
        
        Args:
            speaker_segments: í™”ìë³„ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            í™”ìë³„ í‰ê·  ì„ë² ë”© ë²¡í„°
        """
        speaker_embeddings = {}
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        if not self.embedding_extractor._load_embedding_model():
            raise RuntimeError("ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        for speaker, segment_paths in speaker_segments.items():
            embeddings = []
            
            for segment_path in segment_paths:
                try:
                    # ê°œë³„ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¶”ì¶œ
                    embedding = self.embedding_extractor.extract_embedding_from_file(segment_path)
                    
                    if embedding is not None:
                        embeddings.append(embedding)
                    
                except Exception as e:
                    logger.warning(f"ì„¸ê·¸ë¨¼íŠ¸ {segment_path} ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    continue
            
            if embeddings:
                # í‰ê·  ì„ë² ë”© ê³„ì‚°
                speaker_embeddings[speaker] = np.mean(embeddings, axis=0)
                logger.debug(f"í™”ì {speaker}: {len(embeddings)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ â†’ ì„ë² ë”© í¬ê¸° {speaker_embeddings[speaker].shape}")
            else:
                logger.warning(f"í™”ì {speaker}ì˜ ì„ë² ë”© ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        return speaker_embeddings
    
    def _create_speaker_mapping(self, original_diarization: DiarizationResult, 
                               new_clusters: Dict[int, List[str]]) -> Dict[str, str]:
        """
        ì›ë³¸ í™”ì IDì™€ ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ID ê°„ì˜ ë§¤í•‘ ìƒì„±.
        
        Args:
            original_diarization: ì›ë³¸ í™”ì ë¶„ë¦¬ ê²°ê³¼
            new_clusters: ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ê²°ê³¼
            
        Returns:
            í™”ì ID ë§¤í•‘ (ì›ë³¸ í™”ì ID â†’ ìƒˆë¡œìš´ í™”ì ID)
        """
        speaker_mapping = {}
        
        # ìƒˆë¡œìš´ í™”ì ID ìƒì„± (cluster_0, cluster_1, ...)
        cluster_to_new_id = {}
        for cluster_id in sorted(new_clusters.keys()):
            cluster_to_new_id[cluster_id] = f"speaker_{cluster_id + 1}"
        
        # ì›ë³¸ í™”ìë¥¼ ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„°ì— ë§¤í•‘
        for cluster_id, original_speakers in new_clusters.items():
            new_speaker_id = cluster_to_new_id[cluster_id]
            for original_speaker in original_speakers:
                speaker_mapping[original_speaker] = new_speaker_id
        
        # ë§¤í•‘ë˜ì§€ ì•Šì€ í™”ìë“¤ ì²˜ë¦¬ (í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš°)
        all_original_speakers = set(seg["speaker"] for seg in original_diarization["segments"])
        unmapped_speakers = all_original_speakers - set(speaker_mapping.keys())
        
        for i, unmapped_speaker in enumerate(unmapped_speakers):
            speaker_mapping[unmapped_speaker] = f"speaker_unmapped_{i + 1}"
        
        logger.info(f"í™”ì ë§¤í•‘ ìƒì„±: {len(speaker_mapping)}ê°œ í™”ì")
        for orig, new in speaker_mapping.items():
            logger.debug(f"  {orig} â†’ {new}")
        
        return speaker_mapping
    
    def _apply_speaker_mapping(self, original_diarization: DiarizationResult, 
                              speaker_mapping: Dict[str, str]) -> DiarizationResult:
        """
        í™”ì ID ë§¤í•‘ì„ ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ í™”ì ë¶„ë¦¬ ê²°ê³¼ ìƒì„±.
        
        Args:
            original_diarization: ì›ë³¸ í™”ì ë¶„ë¦¬ ê²°ê³¼
            speaker_mapping: í™”ì ID ë§¤í•‘
            
        Returns:
            ë§¤í•‘ì´ ì ìš©ëœ ìƒˆë¡œìš´ í™”ì ë¶„ë¦¬ ê²°ê³¼
        """
        enhanced_diarization = {
            "segments": [],
            "metadata": original_diarization.get("metadata", {}).copy()
        }
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        enhanced_diarization["metadata"]["enhancement"] = {
            "method": "embedding_based_clustering",
            "original_speakers": len(set(seg["speaker"] for seg in original_diarization["segments"])),
            "enhanced_speakers": len(set(speaker_mapping.values())),
            "speaker_mapping": speaker_mapping
        }
        
        # ì„¸ê·¸ë¨¼íŠ¸ì— ìƒˆë¡œìš´ í™”ì ID ì ìš©
        for segment in original_diarization["segments"]:
            new_segment = segment.copy()
            original_speaker = segment["speaker"]
            new_speaker = speaker_mapping.get(original_speaker, original_speaker)
            new_segment["speaker"] = new_speaker
            enhanced_diarization["segments"].append(new_segment)
        
        return enhanced_diarization
    
    def _evaluate_improvement(self, original: DiarizationResult, enhanced: DiarizationResult,
                             speaker_embeddings: Dict[str, np.ndarray], 
                             new_clusters: Dict[int, List[str]]) -> Dict[str, Any]:
        """
        ê°œì„  íš¨ê³¼ í‰ê°€.
        
        Args:
            original: ì›ë³¸ í™”ì ë¶„ë¦¬ ê²°ê³¼
            enhanced: ê°œì„ ëœ í™”ì ë¶„ë¦¬ ê²°ê³¼
            speaker_embeddings: í™”ìë³„ ì„ë² ë”©
            new_clusters: ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ê²°ê³¼
            
        Returns:
            ê°œì„  íš¨ê³¼ ë©”íŠ¸ë¦­
        """
        # ê¸°ë³¸ í†µê³„
        original_speakers = len(set(seg["speaker"] for seg in original["segments"]))
        enhanced_speakers = len(set(seg["speaker"] for seg in enhanced["segments"]))
        
        # í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ í‰ê°€
        embeddings_array = np.array(list(speaker_embeddings.values()))
        cluster_labels = []
        
        # í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” ìƒì„±
        speaker_to_cluster = {}
        for cluster_id, speakers in new_clusters.items():
            for speaker in speakers:
                speaker_to_cluster[speaker] = cluster_id
        
        for speaker in speaker_embeddings.keys():
            cluster_labels.append(speaker_to_cluster.get(speaker, -1))
        
        cluster_labels = np.array(cluster_labels)
        
        # í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ ë©”íŠ¸ë¦­
        quality_metrics = self.clusterer.validate_clustering_quality(embeddings_array, cluster_labels)
        
        # í™”ì ë¶„ë¦¬ ê²°ê³¼ ë¹„êµ
        comparison_metrics = self.validator.calculate_metrics(original, enhanced)
        
        # ê°œì„  ìš”ì•½
        improvement_summary = f"{original_speakers}ëª… â†’ {enhanced_speakers}ëª… í™”ì"
        if quality_metrics.get("silhouette_score", 0) > 0.5:
            improvement_summary += " (ê³ í’ˆì§ˆ í´ëŸ¬ìŠ¤í„°ë§)"
        
        return {
            "original_speaker_count": original_speakers,
            "enhanced_speaker_count": enhanced_speakers,
            "clustering_quality": quality_metrics,
            "comparison_metrics": comparison_metrics,
            "improvement_summary": improvement_summary
        }
    
    def _cleanup_temp_files(self):
        """ì„ì‹œ íŒŒì¼ ë° í´ë” ì •ë¦¬."""
        try:
            if self.temp_dir.exists():
                # ëª¨ë“  ì„ì‹œ íŒŒì¼ ì‚­ì œ
                for file_path in self.temp_dir.glob("*.wav"):
                    file_path.unlink()
                
                # í´ë”ê°€ ë¹„ì–´ìˆìœ¼ë©´ í´ë”ë„ ì‚­ì œ
                try:
                    self.temp_dir.rmdir()
                    logger.debug("ì„ì‹œ í´ë” ì •ë¦¬ ì™„ë£Œ")
                except OSError:
                    # í´ë”ê°€ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ íŒŒì¼ë§Œ ì •ë¦¬í–ˆë‹¤ê³  ë¡œê·¸
                    logger.debug("ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ (í´ë”ëŠ” ìœ ì§€)")
        except Exception as e:
            logger.warning(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def save_enhancement_results(self, original_result: DiarizationResult, 
                                enhanced_result: DiarizationResult,
                                enhancement_info: Dict, output_path: str):
        """
        ê°œì„  ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥.
        
        Args:
            original_result: ì›ë³¸ ê²°ê³¼
            enhanced_result: ê°œì„ ëœ ê²°ê³¼  
            enhancement_info: ê°œì„  ì •ë³´
            output_path: ì €ì¥ ê²½ë¡œ
        """
        results = {
            "original_diarization": original_result,
            "enhanced_diarization": enhanced_result,
            "enhancement_info": enhancement_info,
            "timestamp": logging.Formatter().formatTime(logging.LogRecord("", 0, "", 0, "", (), None))
        }
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"ê°œì„  ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            logger.error(f"ê°œì„  ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")