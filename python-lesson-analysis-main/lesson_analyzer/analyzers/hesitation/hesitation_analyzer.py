"""ë§ë”ë“¬, ë©ˆì¶¤, ë°œí™” íë¦„ ì¤‘ë‹¨ ë¶„ì„ ëª¨ë“ˆ.

ì´ ëª¨ë“ˆì€ Praat-parselmouthì™€ librosaë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì—ì„œ ë§ë”ë“¬, ë©ˆì¶¤, ë°œí™” íë¦„ ì¤‘ë‹¨ì„ ë¶„ì„í•©ë‹ˆë‹¤.
"""

import os
import json
import logging
from typing import Dict, List, Optional, Tuple, Union, Any
from dataclasses import dataclass

import numpy as np
import librosa
from scipy.stats import gaussian_kde


@dataclass
class PauseInfo:
    """ë©ˆì¶¤ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤."""
    start: float  # ì‹œì‘ ì‹œê°„ (ì´ˆ)
    end: float  # ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
    duration: float  # ì§€ì† ì‹œê°„ (ì´ˆ)
    type: str  # ë©ˆì¶¤ ìœ í˜• ('silent', 'filled')
    filler_word: Optional[str] = None  # ì±„ì›€ë§ (ìˆëŠ” ê²½ìš°)


@dataclass
class SpeechFlowMetrics:
    """ë°œí™” íë¦„ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤."""
    total_duration: float  # ì´ ë°œí™” ì‹œê°„ (ì´ˆ)
    speech_duration: float  # ì‹¤ì œ ë°œí™” ì‹œê°„ (ì´ˆ)
    pause_duration: float  # ì´ ë©ˆì¶¤ ì‹œê°„ (ì´ˆ)
    silent_pause_count: int  # ë¬´ìŒ ë©ˆì¶¤ íšŸìˆ˜
    filled_pause_count: int  # ì±„ì›€ë§ ë©ˆì¶¤ íšŸìˆ˜
    speech_rate: float  # ë°œí™” ì†ë„ (ë‹¨ì–´/ë¶„)
    articulation_rate: float  # ì¡°ìŒ ì†ë„ (ë°œí™” ì‹œê°„ë§Œ ê³ ë ¤í•œ ë‹¨ì–´/ë¶„)
    avg_pause_duration: float  # í‰ê·  ë©ˆì¶¤ ì‹œê°„ (ì´ˆ)
    pause_frequency: float  # ë©ˆì¶¤ ë¹ˆë„ (ë©ˆì¶¤ ìˆ˜/ë¶„)
    pause_to_speech_ratio: float  # ë©ˆì¶¤ ëŒ€ ë°œí™” ë¹„ìœ¨
    hesitation_score: float  # ë§ë”ë“¬ ì ìˆ˜ (0-1, ë†’ì„ìˆ˜ë¡ ë§ë”ë“¬ ë§ìŒ)
    syllable_rate: float = 0.0  # ìŒì ˆ ì†ë„ (ìŒì ˆ/ì´ˆ)
    speech_rate_variability: float = 0.0  # ë°œí™” ì†ë„ ë³€ë™ì„±
    speech_rate_trend: float = 0.0  # ë°œí™” ì†ë„ ì¶”ì„¸ (ì–‘ìˆ˜: ê°€ì†, ìŒìˆ˜: ê°ì†)
    normalized_speech_rate: float = 0.0  # ì •ê·œí™”ëœ ë°œí™” ì†ë„ (z-score)
    fluency_score: float = 0.0  # ìœ ì°½ì„± ì ìˆ˜ (0-1, ë†’ì„ìˆ˜ë¡ ìœ ì°½í•¨)


class HesitationAnalyzer:
    """ë§ë”ë“¬, ë©ˆì¶¤, ë°œí™” íë¦„ ì¤‘ë‹¨ì„ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤."""
    
    def __init__(self, language: str = "en", sample_rate: int = 16000):
        """
        HesitationAnalyzer ì´ˆê¸°í™”.
        
        Args:
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: 'en')
            sample_rate: ì˜¤ë””ì˜¤ ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ê¸°ë³¸ê°’: 16000Hz)
        """
        # ì–¸ì–´ë³„ ì±„ì›€ë§ ì‚¬ì „
        self.filler_words = {
            "en": [
                "um", "uh", "er", "ah", "like", "you know", "so", "well", 
                "I mean", "kind of", "sort of", "basically", "actually", 
                "literally", "right", "okay", "hmm"
            ],
            "ko": [
                "ìŒ", "ì–´", "ê·¸", "ì €", "ë­", "ì•„", "ì´ì œ", "ê·¸ë‹ˆê¹Œ", "ë­ì§€", 
                "ê·¸ëŸ¬ë‹ˆê¹Œ", "ê·¸ë˜ì„œ", "ë­ë¼ê³  í•´ì•¼ ë˜ì§€", "ìˆì–ì•„", "ê·¸ê²Œ", "ê·¸ê±°"
            ]
        }
        
        # ê¸°ë³¸ ì–¸ì–´ ì„¤ì •
        self.language = language
        self.sample_rate = sample_rate
        
        # Praat-parselmouth ì´ˆê¸°í™”
        self.parselmouth = None
        self.praat_call = None
        self._parselmouth_loaded = False
        self._load_parselmouth()
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # ì§„í–‰ ìƒí™© ì½œë°±
        self.progress_callback = None

    def _load_parselmouth(self):
        """Praat-parselmouth ë¡œë“œ."""
        try:
            import parselmouth
            from parselmouth.praat import call
            self.parselmouth = parselmouth
            self.praat_call = call
            self._parselmouth_loaded = True
        except Exception as e:
            self.logger.warning(f"Praat-parselmouth ë¡œë“œ ì‹¤íŒ¨: {e}")
            self._parselmouth_loaded = False
    
    def set_language(self, language: str) -> None:
        """
        ë¶„ì„ ì–¸ì–´ ì„¤ì •.
        
        Args:
            language: ì–¸ì–´ ì½”ë“œ ('en', 'ko' ë“±)
        """
        if language not in self.filler_words:
            self.logger.warning(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì–¸ì–´: {language}. ê¸°ë³¸ ì˜ì–´ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.")
            language = "en"
        
        self.language = language

    def detect_silences_librosa(self, audio_array: np.ndarray, min_silence_duration: float = 0.3, 
                               silence_threshold: float = -40) -> List[Tuple[float, float]]:
        """
        librosaë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì—ì„œ ë¬´ìŒ êµ¬ê°„ íƒì§€.

        Args:
            audio_array: ì˜¤ë””ì˜¤ ë°ì´í„° ë°°ì—´
            min_silence_duration: ìµœì†Œ ë¬´ìŒ êµ¬ê°„ ê¸¸ì´ (ì´ˆ)
            silence_threshold: ë¬´ìŒìœ¼ë¡œ ê°„ì£¼í•  ë°ì‹œë²¨ ì„ê³„ê°’

        Returns:
            ë¬´ìŒ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸ [(ì‹œì‘ ì‹œê°„, ì¢…ë£Œ ì‹œê°„), ...]
        """
        # ì˜¤ë””ì˜¤ ì§„í­ ê³„ì‚°
        amplitude = librosa.amplitude_to_db(np.abs(librosa.stft(audio_array)), ref=np.max)
        amplitude_mean = np.mean(amplitude, axis=0)
        
        # ë¬´ìŒ êµ¬ê°„ ë§ˆìŠ¤í¬ ìƒì„±
        silence_mask = amplitude_mean < silence_threshold
        
        # ì—°ì†ëœ ë¬´ìŒ êµ¬ê°„ ì°¾ê¸°
        silences = []
        in_silence = False
        start_idx = 0
        
        for i, is_silence in enumerate(silence_mask):
            if is_silence and not in_silence:
                # ë¬´ìŒ ì‹œì‘
                in_silence = True
                start_idx = i
            elif not is_silence and in_silence:
                # ë¬´ìŒ ì¢…ë£Œ
                in_silence = False
                duration = (i - start_idx) * librosa.get_duration(y=audio_array) / len(silence_mask)
                
                if duration >= min_silence_duration:
                    start_time = start_idx * librosa.get_duration(y=audio_array) / len(silence_mask)
                    end_time = i * librosa.get_duration(y=audio_array) / len(silence_mask)
                    silences.append((start_time, end_time))
        
        # ë§ˆì§€ë§‰ ë¬´ìŒ êµ¬ê°„ ì²˜ë¦¬
        if in_silence:
            duration = (len(silence_mask) - start_idx) * librosa.get_duration(y=audio_array) / len(silence_mask)
            
            if duration >= min_silence_duration:
                start_time = start_idx * librosa.get_duration(y=audio_array) / len(silence_mask)
                end_time = librosa.get_duration(y=audio_array)
                silences.append((start_time, end_time))
                
        return silences

    def detect_silences_with_praat_stable(self, audio_path: str, start_time: float = 0, end_time: Optional[float] = None,
                                          min_silence_duration: float = 0.3, silence_threshold: float = -25) -> List[Dict]:
        """
        ì•ˆì •ì ì¸ praat-parselmouthë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì—ì„œ ë¬´ìŒ êµ¬ê°„ íƒì§€.
        ë³µì¡í•œ TextGrid í•¨ìˆ˜ ëŒ€ì‹  ê¸°ë³¸ì ì¸ Intensity ë¶„ì„ ì‚¬ìš©.

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            start_time: ë¶„ì„ ì‹œì‘ ì‹œê°„ (ì´ˆ)
            end_time: ë¶„ì„ ì¢…ë£Œ ì‹œê°„ (ì´ˆ), Noneì´ë©´ íŒŒì¼ ëê¹Œì§€
            min_silence_duration: ìµœì†Œ ë¬´ìŒ êµ¬ê°„ ê¸¸ì´ (ì´ˆ)
            silence_threshold: ë¬´ìŒìœ¼ë¡œ ê°„ì£¼í•  ë°ì‹œë²¨ ì„ê³„ê°’

        Returns:
            ë¬´ìŒ êµ¬ê°„ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        if not self._parselmouth_loaded:
            self._load_parselmouth()
            
        if not self._parselmouth_loaded:
            raise RuntimeError("Praat-parselmouthë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        if end_time is None:
            # ì „ì²´ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
            sound = self.parselmouth.Sound(audio_path)
            if start_time > 0:
                sound = sound.extract_part(from_time=start_time)
                start_time = 0  # ì¶”ì¶œ í›„ ì‹œì‘ì  ì¬ì„¤ì •
        else:
            # ì§€ì •ëœ êµ¬ê°„ë§Œ ë¡œë“œ
            y, sr = librosa.load(audio_path, sr=self.sample_rate, offset=start_time, 
                                duration=(end_time - start_time))
            sound = self.parselmouth.Sound(y, sampling_frequency=sr)
            end_time = end_time - start_time  # ìƒëŒ€ ì‹œê°„ìœ¼ë¡œ ì¡°ì •
            start_time = 0
            
        # Intensity ë¶„ì„ (ë” ì•ˆì •ì )
        intensity = sound.to_intensity(minimum_pitch=75.0)  # ìµœì†Œ í”¼ì¹˜ ëª…ì‹œ
        
        # ì‹œê°„ ë°°ì—´ê³¼ ê°•ë„ ê°’ ì¶”ì¶œ
        times = intensity.xs()
        intensities = intensity.values[0]
        
        # dB ë³€í™˜ (ì´ë¯¸ dB ë‹¨ìœ„ì´ì§€ë§Œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        # NaN ê°’ì„ ë§¤ìš° ë‚®ì€ ê°’ìœ¼ë¡œ ëŒ€ì²´
        intensities = np.where(np.isnan(intensities), -80.0, intensities)
        
        # ë¬´ìŒ êµ¬ê°„ ê°ì§€
        silences = []
        in_silence = False
        silence_start = 0
        
        for i, (time, intensity_db) in enumerate(zip(times, intensities)):
            is_silent = intensity_db < silence_threshold
            
            if is_silent and not in_silence:
                # ë¬´ìŒ ì‹œì‘
                in_silence = True
                silence_start = time
            elif not is_silent and in_silence:
                # ë¬´ìŒ ì¢…ë£Œ
                in_silence = False
                silence_duration = time - silence_start
                
                if silence_duration >= min_silence_duration:
                    silences.append({
                        "start": start_time + silence_start,
                        "end": start_time + time,
                        "duration": silence_duration
                    })
        
        # ë§ˆì§€ë§‰ ë¬´ìŒ êµ¬ê°„ ì²˜ë¦¬
        if in_silence and len(times) > 0:
            silence_duration = times[-1] - silence_start
            if silence_duration >= min_silence_duration:
                silences.append({
                    "start": start_time + silence_start,
                    "end": start_time + times[-1],
                    "duration": silence_duration
                })
        
        self.logger.debug(f"ğŸ” Praat Intensity ë¶„ì„: {len(times)}ê°œ ìƒ˜í”Œ, {len(silences)}ê°œ ë¬´ìŒ êµ¬ê°„")
        return silences

    def detect_silences_with_praat(self, audio_path: str, start_time: float = 0, end_time: Optional[float] = None,
                                   min_silence_duration: float = 0.3, silence_threshold: float = -25,
                                   min_sounding_duration: float = 0.1) -> List[Dict]:
        """
        ë³µì¡í•œ praat-parselmouth TextGrid ê¸°ë°˜ ë¬´ìŒ êµ¬ê°„ íƒì§€ (ë ˆê±°ì‹œ - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ).
        ì•ˆì •ì„± ë¬¸ì œë¡œ detect_silences_with_praat_stable ì‚¬ìš© ê¶Œì¥.
        """
        # ë” ì•ˆì •ì ì¸ í•¨ìˆ˜ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        return self.detect_silences_with_praat_stable(audio_path, start_time, end_time, 
                                                     min_silence_duration, silence_threshold)

    def analyze_with_parselmouth(self, audio_path: str) -> Dict:
        """
        Praat-parselmouthë¥¼ ì‚¬ìš©í•œ ë°œì„± ë¶„ì„.

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

        Returns:
            ë°œì„± ë¶„ì„ ê²°ê³¼ (í”¼ì¹˜, í¬ë¨¼íŠ¸, ë¬´ìŒ êµ¬ê°„ ë“±)
        """
        if not self._parselmouth_loaded:
            self._load_parselmouth()
            
        if not self._parselmouth_loaded:
            raise RuntimeError("Praat-parselmouthë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        sound = self.parselmouth.Sound(audio_path)
        
        # í”¼ì¹˜ ë¶„ì„
        pitch = sound.to_pitch()
        pitch_values = pitch.selected_array['frequency']
        pitch_times = pitch.xs()
        
        # ë¬´ìŒ êµ¬ê°„ ë¶„ì„
        intensity = sound.to_intensity()
        intensity_values = intensity.values[0]
        intensity_times = intensity.xs()
        
        # ê²°ê³¼ ì €ì¥
        result = {
            "pitch": {
                "times": pitch_times.tolist(),
                "values": pitch_values.tolist()
            },
            "intensity": {
                "times": intensity_times.tolist(),
                "values": intensity_values.tolist()
            }
        }
        
        return result

    def _calculate_hesitation_score(self, silence_ratio: float, filler_density: float) -> float:
        """
        ì£¼ì €í•¨ ì ìˆ˜ ê³„ì‚° (0-1 ì‚¬ì´ì˜ ê°’, ë†’ì„ìˆ˜ë¡ ì£¼ì €í•¨ì´ ë§ìŒ).
        
        Args:
            silence_ratio: ë¬´ìŒ êµ¬ê°„ ë¹„ìœ¨ (0-1)
            filler_density: ì±„ì›€ì–´ ë°€ë„
            
        Returns:
            ì£¼ì €í•¨ ì ìˆ˜ (0-1)
        """
        # ë¬´ìŒ êµ¬ê°„ ë¹„ìœ¨ê³¼ ì±„ì›€ì–´ ë°€ë„ë¥¼ ê°€ì¤‘ì¹˜ë¥¼ ë‘ì–´ ê²°í•©
        # ë¬´ìŒ êµ¬ê°„ì´ ë„ˆë¬´ ë§ê±°ë‚˜ ì±„ì›€ì–´ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ì €í•¨ì´ ë§ë‹¤ê³  íŒë‹¨
        silence_weight = 0.6
        filler_weight = 0.4
        
        # ì±„ì›€ì–´ ë°€ë„ëŠ” ìƒí•œì„  ì„¤ì • (0.05 = 20ë‹¨ì–´ë‹¹ 1ê°œì˜ ì±„ì›€ì–´)
        normalized_filler_density = min(filler_density / 0.05, 1.0)
        
        # ë¬´ìŒ êµ¬ê°„ ë¹„ìœ¨ë„ ìƒí•œì„  ì„¤ì • (0.4 = 40%ê°€ ë¬´ìŒ)
        normalized_silence_ratio = min(silence_ratio / 0.4, 1.0)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        hesitation_score = (silence_weight * normalized_silence_ratio + 
                           filler_weight * normalized_filler_density)
        
        return min(1.0, max(0.0, hesitation_score))

    def detect_pauses(self, audio_path: str, start_time: float = 0, end_time: Optional[float] = None, 
                     min_pause_duration: float = 0.3, silence_threshold: float = -25) -> List[PauseInfo]:
        """
        ì˜¤ë””ì˜¤ì—ì„œ ë©ˆì¶¤ ê°ì§€ (ì•ˆì •ì ì¸ praat-parselmouth ê¸°ë°˜).
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            start_time: ë¶„ì„ ì‹œì‘ ì‹œê°„ (ì´ˆ)
            end_time: ë¶„ì„ ì¢…ë£Œ ì‹œê°„ (ì´ˆ), Noneì´ë©´ íŒŒì¼ ëê¹Œì§€
            min_pause_duration: ìµœì†Œ ë©ˆì¶¤ ì§€ì† ì‹œê°„ (ì´ˆ)
            silence_threshold: ë¬´ìŒ ê°ì§€ ì„ê³„ê°’ (dB)
            
        Returns:
            ê°ì§€ëœ ë©ˆì¶¤ ì •ë³´ ëª©ë¡
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
        
        try:
            # praat-parselmouth ê¸°ë°˜ ì•ˆì •ì ì¸ ë¬´ìŒ ê°ì§€ ì‹œë„
            silence_dicts = self.detect_silences_with_praat_stable(
                audio_path, start_time, end_time, 
                min_pause_duration, silence_threshold
            )
            self.logger.info(f"âœ… praat-parselmouth ê¸°ë°˜ ë¬´ìŒ ê°ì§€ ì„±ê³µ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ praat-parselmouth ì‹¤íŒ¨ ({e}), librosaë¡œ ëŒ€ì²´")
            # librosa ê¸°ë°˜ ë¬´ìŒ êµ¬ê°„ íƒì§€ë¡œ í´ë°±
            y, sr = librosa.load(audio_path, sr=self.sample_rate, offset=start_time, 
                                duration=(end_time - start_time) if end_time else None)
            
            silence_ranges = self.detect_silences_librosa(y, min_pause_duration, silence_threshold)
            
            silence_dicts = []
            for start, end in silence_ranges:
                absolute_start = start_time + start
                absolute_end = start_time + end
                duration = absolute_end - absolute_start
                
                if duration >= min_pause_duration:
                    silence_dicts.append({
                        "start": absolute_start,
                        "end": absolute_end,
                        "duration": duration
                    })
        
        # PauseInfo ê°ì²´ë¡œ ë³€í™˜
        silences = []
        for silence_dict in silence_dicts:
            silences.append(PauseInfo(
                start=silence_dict["start"],
                end=silence_dict["end"],
                duration=silence_dict["duration"],
                type="silent"
            ))
        
        self.logger.info(f"{len(silences)}ê°œì˜ ë¬´ìŒ ë©ˆì¶¤ ê°ì§€ë¨")
        return silences

    def detect_filled_pauses(self, transcripts: List[Dict], confidence_threshold: float = 0.7,
                           speaker_id: Optional[str] = None, custom_fillers: Optional[List[str]] = None) -> List[PauseInfo]:
        """
        ì „ì‚¬ ê²°ê³¼ì—ì„œ ì±„ì›€ë§ ë©ˆì¶¤ ê°ì§€.
        
        Args:
            transcripts: ì „ì‚¬ ê²°ê³¼ ëª©ë¡ (ê° í•­ëª©ì€ {"start": ì‹œì‘ì‹œê°„, "end": ì¢…ë£Œì‹œê°„, "text": í…ìŠ¤íŠ¸} í˜•ì‹)
            confidence_threshold: ì±„ì›€ë§ ê°ì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
            speaker_id: í™”ì ID (ì„ íƒì )
            custom_fillers: ì‚¬ìš©ì ì •ì˜ ì±„ì›€ë§ ëª©ë¡ (ì„ íƒì )
            
        Returns:
            ê°ì§€ëœ ì±„ì›€ë§ ë©ˆì¶¤ ì •ë³´ ëª©ë¡
        """
        filled_pauses = []
        
        # ê¸°ë³¸ ì±„ì›€ë§ ëª©ë¡
        current_language_fillers = self.filler_words.get(self.language, self.filler_words["en"])
        
        # ì‚¬ìš©ì ì •ì˜ ì±„ì›€ë§ì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
        if custom_fillers:
            current_language_fillers = current_language_fillers + custom_fillers
        
        # í™”ìë³„ ì „ì‚¬ë¬¸ í•„í„°ë§
        filtered_transcripts = transcripts
        if speaker_id is not None:
            filtered_transcripts = [t for t in transcripts if t.get("speaker_id") == speaker_id]
        
        # ì±„ì›€ë§ ê°ì§€
        for transcript in filtered_transcripts:
            start_time = transcript.get("start", 0)
            end_time = transcript.get("end", 0)
            text = transcript.get("text", "").lower()
            current_speaker = transcript.get("speaker_id", speaker_id)
            
            # ì±„ì›€ë§ ê°ì§€
            for filler in current_language_fillers:
                if filler in text.lower():
                    # ì±„ì›€ë§ ìœ„ì¹˜ ë° ì§€ì† ì‹œê°„ ì¶”ì •
                    words = text.split()
                    word_count = len(words)
                    segment_duration = end_time - start_time
                    
                    if word_count > 0:
                        word_duration = segment_duration / word_count
                        
                        # ê° ë‹¨ì–´ ìœ„ì¹˜ì—ì„œ ì±„ì›€ë§ ê²€ìƒ‰
                        for i, word in enumerate(words):
                            if filler in word or word in filler:
                                # ì±„ì›€ë§ ì‹œì‘/ì¢…ë£Œ ì‹œê°„ ì¶”ì •
                                filler_start = start_time + (i * word_duration)
                                filler_end = filler_start + word_duration
                                
                                filled_pauses.append(PauseInfo(
                                    start=filler_start,
                                    end=filler_end,
                                    duration=word_duration,
                                    type="filled",
                                    filler_word=filler
                                ))
        
        self.logger.info(f"{len(filled_pauses)}ê°œì˜ ì±„ì›€ë§ ë©ˆì¶¤ ê°ì§€ë¨")
        return filled_pauses
        
    def learn_speaker_specific_fillers(self, transcripts: List[Dict], speaker_id: Optional[str] = None,
                                      min_frequency: int = 3, min_confidence: float = 0.7) -> List[str]:
        """
        í™”ìë³„ ë§ì¶¤í˜• ì±„ì›€ë§ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.
        
        Args:
            transcripts: ì „ì‚¬ ê²°ê³¼ ëª©ë¡
            speaker_id: í™”ì ID (ì„ íƒì )
            min_frequency: ìµœì†Œ ë°œìƒ ë¹ˆë„
            min_confidence: ìµœì†Œ ì‹ ë¢°ë„
            
        Returns:
            í™”ìë³„ ë§ì¶¤í˜• ì±„ì›€ë§ ëª©ë¡
        """
        # í™”ìë³„ ì „ì‚¬ë¬¸ í•„í„°ë§
        filtered_transcripts = transcripts
        if speaker_id is not None:
            filtered_transcripts = [t for t in transcripts if t.get("speaker_id") == speaker_id]
        
        if not filtered_transcripts:
            return []
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        all_text = " ".join([t.get("text", "").lower() for t in filtered_transcripts])
        words = all_text.split()
        
        # ë‹¨ì–´ ë¹ˆë„ ë¶„ì„
        word_freq = {}
        for i in range(len(words)):
            word = words[i]
            if len(word) <= 1:  # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ ì œì™¸
                continue
                
            # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
            if word not in word_freq:
                word_freq[word] = 0
            word_freq[word] += 1
            
            # ë‹¨ì–´ ì¡°í•© ì²˜ë¦¬ (2-gram)
            if i < len(words) - 1:
                bigram = f"{word} {words[i+1]}"
                if bigram not in word_freq:
                    word_freq[bigram] = 0
                word_freq[bigram] += 1
        
        # ê¸°ì¡´ ì±„ì›€ë§ ëª©ë¡
        current_language_fillers = set(self.filler_words.get(self.language, self.filler_words["en"]))
        
        # ìƒˆë¡œìš´ ì±„ì›€ë§ í›„ë³´ ì¶”ì¶œ
        candidate_fillers = []
        for word, freq in word_freq.items():
            # ìµœì†Œ ë¹ˆë„ ë° ê¸°ì¡´ ì±„ì›€ë§ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì²˜ë¦¬
            if freq >= min_frequency and word not in current_language_fillers:
                # ë¬¸ì¥ ì‹œì‘/ì¢…ë£Œì— ë‚˜íƒ€ë‚˜ëŠ” ë¹ˆë„ ê³„ì‚°
                sentence_start_count = 0
                sentence_middle_count = 0
                
                for transcript in filtered_transcripts:
                    text = transcript.get("text", "").lower()
                    sentences = text.split(".")
                    
                    for sentence in sentences:
                        if not sentence.strip():
                            continue
                            
                        words_in_sentence = sentence.strip().split()
                        if not words_in_sentence:
                            continue
                            
                        # ë¬¸ì¥ ì‹œì‘ì— ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸
                        if word in words_in_sentence[0]:
                            sentence_start_count += 1
                        # ë¬¸ì¥ ì¤‘ê°„ì— ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸
                        elif word in " ".join(words_in_sentence[1:]):
                            sentence_middle_count += 1
                
                # ì±„ì›€ë§ ê°€ëŠ¥ì„± ì ìˆ˜ ê³„ì‚°
                total_occurrences = sentence_start_count + sentence_middle_count
                if total_occurrences > 0:
                    start_ratio = sentence_start_count / total_occurrences
                    confidence = 0.5  # ê¸°ë³¸ ì‹ ë¢°ë„
                    
                    # ë¬¸ì¥ ì‹œì‘ì— ë‚˜íƒ€ë‚˜ëŠ” ë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡ ì±„ì›€ë§ ê°€ëŠ¥ì„± ì¦ê°€
                    if start_ratio > 0.3:
                        confidence += 0.2
                    
                    # ì§§ì€ ë‹¨ì–´ì¼ìˆ˜ë¡ ì±„ì›€ë§ ê°€ëŠ¥ì„± ì¦ê°€
                    if len(word.split()) == 1 and len(word) <= 5:
                        confidence += 0.1
                    
                    # ë¹ˆë„ê°€ ë†’ì„ìˆ˜ë¡ ì±„ì›€ë§ ê°€ëŠ¥ì„± ì¦ê°€
                    if freq > min_frequency * 2:
                        confidence += 0.2
                    
                    if confidence >= min_confidence:
                        candidate_fillers.append(word)
        
        self.logger.info(f"{len(candidate_fillers)}ê°œì˜ í™”ìë³„ ë§ì¶¤í˜• ì±„ì›€ë§ íŒ¨í„´ ë°œê²¬ë¨")
        return candidate_fillers
    
    def calculate_syllable_count(self, text: str, language: Optional[str] = None) -> int:
        """
        í…ìŠ¤íŠ¸ì˜ ìŒì ˆ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: í˜„ì¬ ì„¤ì •ëœ ì–¸ì–´)
            
        Returns:
            ìŒì ˆ ìˆ˜
        """
        if language is None:
            language = self.language
            
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        text = text.strip().lower()
        
        if language == "ko":
            # í•œêµ­ì–´ ìŒì ˆ ìˆ˜ ê³„ì‚° (í•œê¸€ ìëª¨ ê¸°ì¤€)
            syllable_count = 0
            for char in text:
                if 'ê°€' <= char <= 'í£':  # í•œê¸€ ë²”ìœ„
                    syllable_count += 1
            return max(1, syllable_count)  # ìµœì†Œ 1 ë°˜í™˜
        else:
            # ì˜ì–´ ìŒì ˆ ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
            # ëª¨ìŒ ê°œìˆ˜ ê¸°ë°˜ ìŒì ˆ ìˆ˜ ì¶”ì •
            vowels = "aeiouy"
            count = 0
            prev_is_vowel = False
            
            for char in text:
                is_vowel = char in vowels
                if is_vowel and not prev_is_vowel:
                    count += 1
                prev_is_vowel = is_vowel
                
            # ìŒì ˆì´ ì—†ëŠ” ê²½ìš° ìµœì†Œ 1 ë°˜í™˜
            return max(1, count)
    
    def calculate_speech_rate_metrics(self, transcripts: List[Dict], total_duration: float) -> Dict[str, float]:
        """
        ë°œí™” ì†ë„ ê´€ë ¨ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            transcripts: ì „ì‚¬ ê²°ê³¼ ëª©ë¡
            total_duration: ì´ ë°œí™” ì‹œê°„ (ì´ˆ)
            
        Returns:
            ë°œí™” ì†ë„ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
        """
        if not transcripts or total_duration <= 0:
            return {
                "speech_rate": 0,
                "speech_rate_variability": 0,
                "speech_rate_trend": 0,
                "normalized_speech_rate": 0,
                "syllable_rate": 0
            }
        
        # ì„¸ê·¸ë¨¼íŠ¸ë³„ ë°œí™” ì†ë„ ê³„ì‚°
        segment_rates = []
        segment_syllable_rates = []
        total_words = 0
        total_syllables = 0
        
        for transcript in transcripts:
            text = transcript.get("text", "")
            if not text.strip():
                continue
                
            start_time = transcript.get("start", 0)
            end_time = transcript.get("end", 0)
            segment_duration = end_time - start_time
            
            if segment_duration <= 0:
                continue
                
            # ë‹¨ì–´ ìˆ˜ ê³„ì‚°
            words = text.split()
            word_count = len(words)
            total_words += word_count
            
            # ìŒì ˆ ìˆ˜ ê³„ì‚°
            syllable_count = self.calculate_syllable_count(text)
            total_syllables += syllable_count
            
            # ì„¸ê·¸ë¨¼íŠ¸ë³„ ë°œí™” ì†ë„ (ë‹¨ì–´/ë¶„)
            segment_rate = (word_count / segment_duration) * 60
            segment_rates.append(segment_rate)
            
            # ì„¸ê·¸ë¨¼íŠ¸ë³„ ìŒì ˆ ì†ë„ (ìŒì ˆ/ì´ˆ)
            segment_syllable_rate = syllable_count / segment_duration
            segment_syllable_rates.append(segment_syllable_rate)
        
        # ì „ì²´ ë°œí™” ì†ë„ (ë‹¨ì–´/ë¶„)
        speech_rate = (total_words / total_duration) * 60 if total_words > 0 else 0
        
        # ì „ì²´ ìŒì ˆ ì†ë„ (ìŒì ˆ/ì´ˆ)
        syllable_rate = total_syllables / total_duration if total_syllables > 0 else 0
        
        # ë°œí™” ì†ë„ ë³€ë™ì„± (í‘œì¤€ í¸ì°¨)
        speech_rate_variability = np.std(segment_rates) if len(segment_rates) > 1 else 0
        
        # ë°œí™” ì†ë„ ì¶”ì„¸ (ì„ í˜• íšŒê·€ ê¸°ìš¸ê¸°)
        speech_rate_trend = 0
        if len(segment_rates) > 2:
            x = np.arange(len(segment_rates))
            try:
                slope, _, _, _, _ = np.polyfit(x, segment_rates, 1, full=True)
                speech_rate_trend = slope[0]
            except:
                speech_rate_trend = 0
        
        # ì •ê·œí™”ëœ ë°œí™” ì†ë„ (z-score)
        normalized_speech_rate = 0
        if speech_rate > 0:
            # ì˜ì–´ ê¸°ì¤€ í‰ê·  ë°œí™” ì†ë„: ~150 ë‹¨ì–´/ë¶„, í‘œì¤€ í¸ì°¨: ~30
            # í•œêµ­ì–´ ê¸°ì¤€ í‰ê·  ë°œí™” ì†ë„: ~220 ìŒì ˆ/ë¶„, í‘œì¤€ í¸ì°¨: ~40
            if self.language == "ko":
                avg_rate = 220 / 60  # ìŒì ˆ/ì´ˆ
                std_rate = 40 / 60  # ìŒì ˆ/ì´ˆ
                normalized_speech_rate = (syllable_rate - avg_rate) / std_rate
            else:
                avg_rate = 150  # ë‹¨ì–´/ë¶„
                std_rate = 30  # ë‹¨ì–´/ë¶„
                normalized_speech_rate = (speech_rate - avg_rate) / std_rate
        
        return {
            "speech_rate": speech_rate,
            "speech_rate_variability": speech_rate_variability,
            "speech_rate_trend": speech_rate_trend,
            "normalized_speech_rate": normalized_speech_rate,
            "syllable_rate": syllable_rate
        }
    
    def analyze_speech_flow(self, audio_path: str, transcripts: List[Dict], 
                           start_time: float = 0, end_time: Optional[float] = None,
                           min_pause_duration: float = 0.3, silence_threshold: float = -25,
                           speaker_id: Optional[str] = None) -> SpeechFlowMetrics:
        """
        ë°œí™” íë¦„ ë¶„ì„ ìˆ˜í–‰.
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            transcripts: ì „ì‚¬ ê²°ê³¼ ëª©ë¡
            start_time: ë¶„ì„ ì‹œì‘ ì‹œê°„ (ì´ˆ)
            end_time: ë¶„ì„ ì¢…ë£Œ ì‹œê°„ (ì´ˆ), Noneì´ë©´ íŒŒì¼ ëê¹Œì§€
            min_pause_duration: ìµœì†Œ ë©ˆì¶¤ ì§€ì† ì‹œê°„ (ì´ˆ)
            silence_threshold: ë¬´ìŒ ê°ì§€ ì„ê³„ê°’ (dB)
            speaker_id: í™”ì ID (ì„ íƒì )
            
        Returns:
            ë°œí™” íë¦„ ë©”íŠ¸ë¦­
        """
        # í™”ìë³„ ì „ì‚¬ë¬¸ í•„í„°ë§ ë° ì‹œê°„ ë²”ìœ„ ì¡°ì •
        filtered_transcripts, start_time, end_time = self._filter_and_adjust_timerange(
            transcripts, speaker_id, start_time, end_time, audio_path
        )
        
        total_duration = end_time - start_time
        
        # ë©ˆì¶¤ ê°ì§€
        pause_data = self._detect_all_pauses(
            audio_path, filtered_transcripts, start_time, end_time, 
            min_pause_duration, silence_threshold, speaker_id
        )
        
        # ë°œí™” ë©”íŠ¸ë¦­ ê³„ì‚°
        speech_metrics = self._calculate_speech_metrics(
            filtered_transcripts, total_duration, pause_data
        )
        
        # ë§ë”ë“¬ ë° ìœ ì°½ì„± ì ìˆ˜ ê³„ì‚°
        scores = self._calculate_hesitation_fluency_scores(
            pause_data, speech_metrics, filtered_transcripts
        )
        
        # ìµœì¢… ê²°ê³¼ êµ¬ì„±
        metrics = self._build_speech_flow_metrics(
            total_duration, pause_data, speech_metrics, scores
        )
        
        # ë¶„ì„ ê²°ê³¼ ë¡œê¹…
        self._log_analysis_results(speech_metrics, pause_data, scores)
        
        return metrics
    
    def _filter_and_adjust_timerange(self, transcripts: List[Dict], speaker_id: Optional[str], 
                                   start_time: float, end_time: Optional[float], 
                                   audio_path: str) -> Tuple[List[Dict], float, float]:
        """í™”ìë³„ ì „ì‚¬ë¬¸ í•„í„°ë§ ë° ì‹œê°„ ë²”ìœ„ ì¡°ì •."""
        filtered_transcripts = transcripts
        
        if speaker_id is not None:
            filtered_transcripts = [t for t in transcripts if t.get("speaker_id") == speaker_id]
            
            # í™”ìë³„ ì‹œê°„ ë²”ìœ„ ì¡°ì •
            if filtered_transcripts:
                speaker_start = min([t.get("start", start_time) for t in filtered_transcripts])
                speaker_end = max([t.get("end", end_time or 0) for t in filtered_transcripts])
                
                start_time = max(start_time, speaker_start)
                if end_time is not None:
                    end_time = min(end_time, speaker_end)
                else:
                    end_time = speaker_end
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´ í™•ì¸
        if end_time is None:
            end_time = librosa.get_duration(path=audio_path)
        
        return filtered_transcripts, start_time, end_time
    
    def _detect_all_pauses(self, audio_path: str, transcripts: List[Dict], 
                         start_time: float, end_time: float, min_pause_duration: float, 
                         silence_threshold: float, speaker_id: Optional[str]) -> Dict:
        """ë¬´ìŒ ë©ˆì¶¤ê³¼ ì±„ì›€ë§ ë©ˆì¶¤ ê°ì§€."""
        # ë¬´ìŒ ë©ˆì¶¤ ê°ì§€
        silent_pauses = self.detect_pauses(
            audio_path, start_time, end_time, min_pause_duration, silence_threshold
        )
        
        # í™”ìë³„ ë§ì¶¤í˜• ì±„ì›€ë§ í•™ìŠµ
        custom_fillers = []
        if speaker_id is not None:
            custom_fillers = self.learn_speaker_specific_fillers(transcripts, speaker_id)
        
        # ì±„ì›€ë§ ë©ˆì¶¤ ê°ì§€
        filled_pauses = self.detect_filled_pauses(
            transcripts, speaker_id=speaker_id, custom_fillers=custom_fillers
        )
        
        # ì¼ì‹œì¤‘ì§€ íŒ¨í„´ ë¶„ì„
        pause_patterns = self.analyze_pause_patterns(silent_pauses, filled_pauses, transcripts)
        
        return {
            'silent_pauses': silent_pauses,
            'filled_pauses': filled_pauses,
            'custom_fillers': custom_fillers,
            'pause_patterns': pause_patterns
        }
    
    def _calculate_speech_metrics(self, transcripts: List[Dict], total_duration: float, 
                                pause_data: Dict) -> Dict:
        """ë°œí™” ê´€ë ¨ ë©”íŠ¸ë¦­ ê³„ì‚°."""
        silent_pauses = pause_data['silent_pauses']
        filled_pauses = pause_data['filled_pauses']
        
        # ì´ ë‹¨ì–´ ìˆ˜ ê³„ì‚°
        total_words = sum(len(t.get("text", "").split()) for t in transcripts)
        
        # ë©ˆì¶¤ ì‹œê°„ ê³„ì‚°
        silent_pause_duration = sum(pause.duration for pause in silent_pauses)
        filled_pause_duration = sum(pause.duration for pause in filled_pauses)
        total_pause_duration = silent_pause_duration + filled_pause_duration
        
        # ì‹¤ì œ ë°œí™” ì‹œê°„ ê³„ì‚°
        speech_duration = total_duration - silent_pause_duration
        
        # ë°œí™” ì†ë„ ê´€ë ¨ ë©”íŠ¸ë¦­ ê³„ì‚°
        speech_rate_metrics = self.calculate_speech_rate_metrics(transcripts, total_duration)
        
        # ì¡°ìŒ ì†ë„ ê³„ì‚°
        articulation_rate = (total_words / speech_duration) * 60 if speech_duration > 0 else 0
        
        # ë©ˆì¶¤ í†µê³„
        total_pauses = len(silent_pauses) + len(filled_pauses)
        avg_pause_duration = total_pause_duration / total_pauses if total_pauses > 0 else 0
        pause_frequency = (total_pauses / total_duration) * 60 if total_duration > 0 else 0
        pause_to_speech_ratio = total_pause_duration / speech_duration if speech_duration > 0 else 0
        
        return {
            'total_words': total_words,
            'speech_duration': speech_duration,
            'total_pause_duration': total_pause_duration,
            'articulation_rate': articulation_rate,
            'avg_pause_duration': avg_pause_duration,
            'pause_frequency': pause_frequency,
            'pause_to_speech_ratio': pause_to_speech_ratio,
            **speech_rate_metrics
        }
    
    def _calculate_hesitation_fluency_scores(self, pause_data: Dict, speech_metrics: Dict, 
                                           transcripts: List[Dict]) -> Dict:
        """ë§ë”ë“¬ ë° ìœ ì°½ì„± ì ìˆ˜ ê³„ì‚°."""
        silent_pauses = pause_data['silent_pauses']
        filled_pauses = pause_data['filled_pauses']
        pause_patterns = pause_data['pause_patterns']
        
        total_pauses = len(silent_pauses) + len(filled_pauses)
        
        # ì •ê·œí™”ëœ ë©”íŠ¸ë¦­ ê³„ì‚°
        normalized_pause_freq = min(1.0, speech_metrics['pause_frequency'] / 20)
        normalized_pause_duration = min(1.0, speech_metrics['avg_pause_duration'] / 2)
        filled_pause_ratio = len(filled_pauses) / total_pauses if total_pauses > 0 else 0
        pattern_correlation = pause_patterns.get("pause_timing_correlation", 0)
        
        # ë§ë”ë“¬ ì ìˆ˜ ê³„ì‚°
        hesitation_score = (
            normalized_pause_freq * 0.30 + 
            normalized_pause_duration * 0.25 + 
            filled_pause_ratio * 0.20 +
            (1 - pattern_correlation) * 0.15 +
            speech_metrics['speech_rate_variability'] * 0.10
        )
        
        # ìœ ì°½ì„± ì ìˆ˜ ê³„ì‚°
        speech_rate_factor = 1.0 - min(1.0, abs(speech_metrics['normalized_speech_rate']) / 2.0)
        fluency_score = (1.0 - hesitation_score) * 0.7 + speech_rate_factor * 0.3
        
        return {
            'hesitation_score': hesitation_score,
            'fluency_score': fluency_score
        }
    
    def _build_speech_flow_metrics(self, total_duration: float, pause_data: Dict, 
                                 speech_metrics: Dict, scores: Dict) -> SpeechFlowMetrics:
        """ìµœì¢… ë°œí™” íë¦„ ë©”íŠ¸ë¦­ êµ¬ì„±."""
        return SpeechFlowMetrics(
            total_duration=total_duration,
            speech_duration=speech_metrics['speech_duration'],
            pause_duration=speech_metrics['total_pause_duration'],
            silent_pause_count=len(pause_data['silent_pauses']),
            filled_pause_count=len(pause_data['filled_pauses']),
            speech_rate=speech_metrics['speech_rate'],
            articulation_rate=speech_metrics['articulation_rate'],
            syllable_rate=speech_metrics['syllable_rate'],
            avg_pause_duration=speech_metrics['avg_pause_duration'],
            pause_frequency=speech_metrics['pause_frequency'],
            pause_to_speech_ratio=speech_metrics['pause_to_speech_ratio'],
            speech_rate_variability=speech_metrics['speech_rate_variability'],
            speech_rate_trend=speech_metrics['speech_rate_trend'],
            normalized_speech_rate=speech_metrics['normalized_speech_rate'],
            hesitation_score=scores['hesitation_score'],
            fluency_score=scores['fluency_score']
        )
    
    def _log_analysis_results(self, speech_metrics: Dict, pause_data: Dict, scores: Dict):
        """ë¶„ì„ ê²°ê³¼ ë¡œê¹…."""
        pause_patterns = pause_data['pause_patterns']
        custom_fillers = pause_data['custom_fillers']
        
        self.logger.info(
            f"ë°œí™” íë¦„ ë¶„ì„ ì™„ë£Œ: ë°œí™” ì†ë„ {speech_metrics['speech_rate']:.2f} ë‹¨ì–´/ë¶„, "
            f"ë©ˆì¶¤ ë¹ˆë„ {speech_metrics['pause_frequency']:.2f} íšŒ/ë¶„"
        )
        self.logger.info(
            f"ì¼ì‹œì¤‘ì§€ íŒ¨í„´ ë¶„ì„: ë¬¸ì¥ ì‹œì‘ ë©ˆì¶¤ {pause_patterns.get('sentence_initial_pauses', 0)}íšŒ, "
            f"ë¬¸ì¥ ë ë©ˆì¶¤ {pause_patterns.get('sentence_final_pauses', 0)}íšŒ"
        )
        
        if custom_fillers:
            filler_list = ', '.join(custom_fillers[:5])
            suffix = '...' if len(custom_fillers) > 5 else ''
            self.logger.info(f"í™”ìë³„ ë§ì¶¤í˜• ì±„ì›€ë§ {len(custom_fillers)}ê°œ ë°œê²¬: {filler_list}{suffix}")
        
    def analyze_pause_patterns(self, silences: List[PauseInfo], filled_pauses: List[PauseInfo], 
                             transcripts: List[Dict]) -> Dict[str, Any]:
        """
        ì¼ì‹œì¤‘ì§€ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            silences: ë¬´ìŒ ì¼ì‹œì¤‘ì§€ ëª©ë¡
            filled_pauses: ì±„ì›€ë§ ì¼ì‹œì¤‘ì§€ ëª©ë¡
            transcripts: ì „ì‚¬ ê²°ê³¼ ëª©ë¡
            
        Returns:
            ì¼ì‹œì¤‘ì§€ íŒ¨í„´ ë¶„ì„ ê²°ê³¼
        """
        # ê²°ê³¼ ì´ˆê¸°í™”
        results = {
            "sentence_initial_pauses": 0,  # ë¬¸ì¥ ì‹œì‘ ì¼ì‹œì¤‘ì§€
            "sentence_final_pauses": 0,   # ë¬¸ì¥ ë ì¼ì‹œì¤‘ì§€
            "mid_sentence_pauses": 0,     # ë¬¸ì¥ ì¤‘ê°„ ì¼ì‹œì¤‘ì§€
            "pause_before_keywords": 0,   # ì¤‘ìš” ë‹¨ì–´ ì• ì¼ì‹œì¤‘ì§€
            "pause_clusters": 0,          # ì¼ì‹œì¤‘ì§€ êµ°ì§‘
            "avg_pause_interval": 0,      # í‰ê·  ì¼ì‹œì¤‘ì§€ ê°„ê²©
            "pause_duration_variance": 0, # ì¼ì‹œì¤‘ì§€ ê¸¸ì´ ë¶„ì‚°
            "pause_distribution": {},     # ì¼ì‹œì¤‘ì§€ ë¶„í¬
            "pause_timing_correlation": 0 # ì¼ì‹œì¤‘ì§€ íƒ€ì´ë°ê³¼ ë¬¸ì¥ êµ¬ì¡°ì˜ ìƒê´€ê´€ê³„
        }
        
        # ì¼ì‹œì¤‘ì§€ê°€ ì—†ëŠ” ê²½ìš°
        if not silences and not filled_pauses:
            return results
        
        # ëª¨ë“  ì¼ì‹œì¤‘ì§€ ëª©ë¡ í•©ì¹˜ê¸°
        all_pauses = silences + filled_pauses
        all_pauses.sort(key=lambda x: x.start)  # ì‹œê°„ìˆœ ì •ë ¬
        
        # ì¼ì‹œì¤‘ì§€ ê¸¸ì´ í†µê³„
        pause_durations = [p.duration for p in all_pauses]
        if pause_durations:
            results["pause_duration_variance"] = np.var(pause_durations)
        
        # ì¼ì‹œì¤‘ì§€ ê°„ê²© ê³„ì‚°
        pause_intervals = []
        for i in range(1, len(all_pauses)):
            interval = all_pauses[i].start - all_pauses[i-1].end
            if interval > 0:
                pause_intervals.append(interval)
        
        if pause_intervals:
            results["avg_pause_interval"] = np.mean(pause_intervals)
        
        # ì¼ì‹œì¤‘ì§€ êµ°ì§‘ ê°ì§€ (0.5ì´ˆ ì´ë‚´ì˜ ì—°ì† ì¼ì‹œì¤‘ì§€)
        cluster_count = 0
        i = 0
        while i < len(all_pauses) - 1:
            if all_pauses[i+1].start - all_pauses[i].end < 0.5:
                cluster_count += 1
                # í˜„ì¬ êµ°ì§‘ ê±´ë„ˆë›°ê¸°
                j = i + 1
                while j < len(all_pauses) - 1 and all_pauses[j+1].start - all_pauses[j].end < 0.5:
                    j += 1
                i = j
            else:
                i += 1
        
        results["pause_clusters"] = cluster_count
        
        # ì¼ì‹œì¤‘ì§€ ë¶„í¬ ë¶„ì„
        if transcripts:
            # ì „ì²´ ì‹œê°„ ë²”ìœ„ ê³„ì‚°
            min_time = min([t.get("start", 0) for t in transcripts])
            max_time = max([t.get("end", 0) for t in transcripts])
            total_time = max_time - min_time
            
            if total_time > 0:
                # 5ë¶„ì˜ 1 ë‹¨ìœ„ë¡œ ë¶„í¬ ê³„ì‚°
                num_bins = 5
                bin_size = total_time / num_bins
                distribution = [0] * num_bins
                
                for pause in all_pauses:
                    bin_index = min(int((pause.start - min_time) / bin_size), num_bins - 1)
                    distribution[bin_index] += 1
                
                # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
                total_pauses = len(all_pauses)
                if total_pauses > 0:
                    distribution = [count / total_pauses * 100 for count in distribution]
                
                results["pause_distribution"] = {
                    f"segment_{i+1}": distribution[i] for i in range(num_bins)
                }
        
        # ë¬¸ì¥ êµ¬ì¡°ì™€ ì¼ì‹œì¤‘ì§€ ê´€ê³„ ë¶„ì„
        sentence_boundaries = []
        for i, transcript in enumerate(transcripts):
            text = transcript.get("text", "")
            # ë¬¸ì¥ ë ê¸°í˜¸ í™•ì¸
            if text.strip().endswith(('.', '!', '?')):
                sentence_boundaries.append(transcript.get("end", 0))
            # ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì‹œì‘ì´ ë¬¸ì¥ ì‹œì‘ì¸ì§€ í™•ì¸
            if i < len(transcripts) - 1:
                next_text = transcripts[i+1].get("text", "")
                if next_text and next_text[0].isupper():
                    sentence_boundaries.append(transcript.get("end", 0))
        
        # ë¬¸ì¥ ê²½ê³„ì—ì„œì˜ ì¼ì‹œì¤‘ì§€ ë¶„ì„
        for pause in all_pauses:
            # ë¬¸ì¥ ì‹œì‘ ì¼ì‹œì¤‘ì§€ í™•ì¸
            for i, transcript in enumerate(transcripts):
                if i > 0 and abs(pause.start - transcript.get("start", 0)) < 0.3:
                    results["sentence_initial_pauses"] += 1
                    break
            
            # ë¬¸ì¥ ë ì¼ì‹œì¤‘ì§€ í™•ì¸
            for boundary in sentence_boundaries:
                if abs(pause.start - boundary) < 0.3:
                    results["sentence_final_pauses"] += 1
                    break
        
        # ë¬¸ì¥ ì¤‘ê°„ ì¼ì‹œì¤‘ì§€ ê³„ì‚°
        results["mid_sentence_pauses"] = len(all_pauses) - results["sentence_initial_pauses"] - results["sentence_final_pauses"]
        
        # ì¤‘ìš” ë‹¨ì–´ ì• ì¼ì‹œì¤‘ì§€ ë¶„ì„
        important_keywords = ["important", "significant", "critical", "essential", "key", "major", "crucial", "vital"]  # ì˜ì–´ í‚¤ì›Œë“œ
        korean_keywords = ["ì¤‘ìš”", "í•„ìˆ˜", "í•µì‹¬", "ê¸°ë³¸", "ê¸°ë³¸ì ", "í•µì‹¬ì "]  # í•œêµ­ì–´ í‚¤ì›Œë“œ
        
        for pause in all_pauses:
            for transcript in transcripts:
                if transcript.get("start", 0) > pause.end and transcript.get("start", 0) - pause.end < 0.3:
                    text = transcript.get("text", "").lower()
                    words = text.split()
                    if words and (words[0] in important_keywords or any(kw in words[0] for kw in korean_keywords)):
                        results["pause_before_keywords"] += 1
                        break
        
        # ì¼ì‹œì¤‘ì§€ íƒ€ì´ë°ê³¼ ë¬¸ì¥ êµ¬ì¡° ìƒê´€ê´€ê³„ ê³„ì‚°
        # ë‹¨ìˆœí™”ëœ ìƒê´€ê´€ê³„ ì ìˆ˜ (0~1)
        if sentence_boundaries and all_pauses:
            correlation_score = (results["sentence_initial_pauses"] + results["sentence_final_pauses"]) / (len(sentence_boundaries) + len(all_pauses)) * 2
            results["pause_timing_correlation"] = min(1.0, correlation_score)
        
        return results
    
    def analyze_speaker_hesitation(self, audio_path: str, diarization_segments: List[Dict], 
                                 transcripts: List[Dict]) -> Dict[str, SpeechFlowMetrics]:
        """
        í™”ìë³„ ë§ë”ë“¬ ë¶„ì„ ìˆ˜í–‰.
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            diarization_segments: í™”ì ë¶„ë¦¬ ì„¸ê·¸ë¨¼íŠ¸ ëª©ë¡
            transcripts: ì „ì‚¬ ê²°ê³¼ ëª©ë¡
            
        Returns:
            í™”ìë³„ ë°œí™” íë¦„ ë©”íŠ¸ë¦­
        """
        # í™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ ê·¸ë£¹í™”
        speaker_segments = {}
        for segment in diarization_segments:
            speaker = segment.get("speaker", "UNKNOWN")
            if speaker not in speaker_segments:
                speaker_segments[speaker] = []
            speaker_segments[speaker].append(segment)
        
        # í™”ìë³„ ì „ì‚¬ ê²°ê³¼ ê·¸ë£¹í™”
        speaker_transcripts = {}
        for transcript in transcripts:
            speaker = transcript.get("speaker", "UNKNOWN")
            if speaker not in speaker_transcripts:
                speaker_transcripts[speaker] = []
            speaker_transcripts[speaker].append(transcript)
        
        # í™”ìë³„ ë¶„ì„ ìˆ˜í–‰ (ìµœì í™”: í™”ìë³„ë¡œ í•œ ë²ˆë§Œ ë¶„ì„)
        speaker_metrics = {}
        for speaker, segments in speaker_segments.items():
            self.logger.info(f"í™”ì {speaker} ë¶„ì„ ì¤‘...")
            
            # í™”ìì˜ ëª¨ë“  ì „ì‚¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            speaker_transcripts_list = speaker_transcripts.get(speaker, [])
            if not speaker_transcripts_list:
                self.logger.warning(f"í™”ì {speaker}ì˜ ì „ì‚¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # í™”ìì˜ ì „ì²´ ì‹œê°„ ë²”ìœ„ ê³„ì‚°
            min_start = min(seg.get("start", 0) for seg in segments)
            max_end = max(seg.get("end", 0) for seg in segments)
            
            # í™”ì ì „ì²´ì— ëŒ€í•´ í•œ ë²ˆë§Œ ë¶„ì„ ìˆ˜í–‰
            try:
                metrics = self.analyze_speech_flow(
                    audio_path, speaker_transcripts_list, min_start, max_end
                )
                speaker_metrics[speaker] = metrics
                self.logger.debug(f"í™”ì {speaker} ë¶„ì„ ì™„ë£Œ: hesitation_score={metrics.hesitation_score:.3f}")
                
            except Exception as e:
                self.logger.error(f"í™”ì {speaker} ë¶„ì„ ì‹¤íŒ¨: {e}")
                # ê¸°ë³¸ ë©”íŠ¸ë¦­ ìƒì„±
                total_duration = max_end - min_start
                total_words = sum(len(t.get("text", "").split()) for t in speaker_transcripts_list)
                
                speaker_metrics[speaker] = SpeechFlowMetrics(
                    total_duration=total_duration,
                    speech_duration=total_duration * 0.8,  # ì¶”ì •ê°’
                    pause_duration=total_duration * 0.2,   # ì¶”ì •ê°’
                    silent_pause_count=5,  # ê¸°ë³¸ê°’
                    filled_pause_count=3,  # ê¸°ë³¸ê°’
                    speech_rate=(total_words / total_duration) * 60 if total_duration > 0 else 0,
                    articulation_rate=(total_words / (total_duration * 0.8)) * 60 if total_duration > 0 else 0,
                    avg_pause_duration=0.5,  # ê¸°ë³¸ê°’
                    pause_frequency=8 * 60 / total_duration if total_duration > 0 else 0,  # 8ê°œ ë©ˆì¶¤ ì¶”ì •
                    pause_to_speech_ratio=0.25,  # ê¸°ë³¸ê°’
                    hesitation_score=0.3  # ê¸°ë³¸ê°’
                )
        
        return speaker_metrics
    
    def visualize_hesitation_analysis(self, metrics: Union[SpeechFlowMetrics, Dict[str, SpeechFlowMetrics]], 
                                    output_path: Optional[str] = None, title: Optional[str] = None) -> None:
        """
        ë§ë”ë“¬ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”.
        
        Args:
            metrics: ë°œí™” íë¦„ ë©”íŠ¸ë¦­ ë˜ëŠ” í™”ìë³„ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
            output_path: ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ (ì„ íƒì )
            title: ê·¸ë˜í”„ ì œëª© (ì„ íƒì )
        """
        try:
            plt = self._import_matplotlib()
            plt.figure(figsize=(15, 10))
            
            if isinstance(metrics, dict):
                self._create_multi_speaker_plots(metrics, title)
            else:
                self._create_single_speaker_plots(metrics, title)
            
            plt.tight_layout()
            self._save_or_show_plot(plt, output_path)
            
        except ImportError as e:
            self.logger.error(f"ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            self.logger.info("ì‹œê°í™”ë¥¼ ìœ„í•´ matplotlibì„ ì„¤ì¹˜í•˜ì„¸ìš”.")
        except Exception as e:
            self.logger.error(f"ì‹œê°í™” ì‹¤íŒ¨: {e}")
    
    def _import_matplotlib(self):
        """matplotlib ì„í¬íŠ¸ ë° ì´ˆê¸°í™”."""
        import matplotlib.pyplot as plt
        from matplotlib.gridspec import GridSpec
        return plt
    
    def _create_multi_speaker_plots(self, metrics: Dict[str, SpeechFlowMetrics], title: Optional[str]):
        """í™”ìë³„ ë¹„êµ ê·¸ë˜í”„ ìƒì„±."""
        import matplotlib.pyplot as plt
        
        speakers = list(metrics.keys())
        data = self._extract_speaker_data(metrics)
        
        self._plot_speaker_hesitation_scores(speakers, data['hesitation_scores'])
        self._plot_speaker_speech_rates(speakers, data['speech_rates'])
        self._plot_speaker_pause_frequencies(speakers, data['pause_frequencies'])
        self._plot_speaker_pause_distribution(speakers, metrics)
        
        if title:
            plt.suptitle(title, fontsize=16)
    
    def _extract_speaker_data(self, metrics: Dict[str, SpeechFlowMetrics]) -> Dict:
        """í™”ìë³„ ë©”íŠ¸ë¦­ ë°ì´í„° ì¶”ì¶œ."""
        return {
            'hesitation_scores': [m.hesitation_score for m in metrics.values()],
            'speech_rates': [m.speech_rate for m in metrics.values()],
            'pause_frequencies': [m.pause_frequency for m in metrics.values()]
        }
    
    def _plot_speaker_hesitation_scores(self, speakers: List[str], scores: List[float]):
        """í™”ìë³„ ë§ë”ë“¬ ì ìˆ˜ ë§‰ëŒ€ ê·¸ë˜í”„."""
        import matplotlib.pyplot as plt
        
        plt.subplot(2, 2, 1)
        plt.bar(speakers, scores, color='skyblue')
        plt.title('Hesitation Score by Speaker')
        plt.ylabel('Hesitation Score (0-1)')
        plt.ylim(0, 1)
        plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    def _plot_speaker_speech_rates(self, speakers: List[str], rates: List[float]):
        """í™”ìë³„ ë°œí™” ì†ë„ ë§‰ëŒ€ ê·¸ë˜í”„."""
        import matplotlib.pyplot as plt
        
        plt.subplot(2, 2, 2)
        plt.bar(speakers, rates, color='lightgreen')
        plt.title('Speech Rate by Speaker')
        plt.ylabel('Words/Minute')
        plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    def _plot_speaker_pause_frequencies(self, speakers: List[str], frequencies: List[float]):
        """í™”ìë³„ ë©ˆì¶¤ ë¹ˆë„ ë§‰ëŒ€ ê·¸ë˜í”„."""
        import matplotlib.pyplot as plt
        
        plt.subplot(2, 2, 3)
        plt.bar(speakers, frequencies, color='salmon')
        plt.title('Pause Frequency by Speaker')
        plt.ylabel('Pauses/Minute')
        plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    def _plot_speaker_pause_distribution(self, speakers: List[str], metrics: Dict[str, SpeechFlowMetrics]):
        """í™”ìë³„ ë©ˆì¶¤ ìœ í˜• íŒŒì´ ì°¨íŠ¸."""
        import matplotlib.pyplot as plt
        
        plt.subplot(2, 2, 4)
        for speaker in speakers:
            silent_count = metrics[speaker].silent_pause_count
            filled_count = metrics[speaker].filled_pause_count
            
            if silent_count + filled_count > 0:
                plt.pie([silent_count, filled_count], 
                      labels=['Silent Pauses', 'Filled Pauses'],
                      autopct='%1.1f%%',
                      startangle=90,
                      colors=['lightblue', 'lightcoral'])
                plt.title(f'{speaker} Pause Type Distribution')
                break
    
    def _create_single_speaker_plots(self, metrics: SpeechFlowMetrics, title: Optional[str]):
        """ë‹¨ì¼ í™”ì ê·¸ë˜í”„ ìƒì„±."""
        import matplotlib.pyplot as plt
        
        self._plot_pause_type_distribution(metrics)
        self._plot_speech_vs_pause_time(metrics)
        self._plot_key_metrics_bar(metrics)
        self._plot_hesitation_gauge(metrics)
        
        if title:
            plt.suptitle(title, fontsize=16)
    
    def _plot_pause_type_distribution(self, metrics: SpeechFlowMetrics):
        """ë©ˆì¶¤ ìœ í˜• ë¶„í¬ íŒŒì´ ì°¨íŠ¸."""
        import matplotlib.pyplot as plt
        
        plt.subplot(2, 2, 1)
        silent_count = metrics.silent_pause_count
        filled_count = metrics.filled_pause_count
        
        if silent_count + filled_count > 0:
            plt.pie([silent_count, filled_count], 
                  labels=['Silent Pauses', 'Filled Pauses'],
                  autopct='%1.1f%%',
                  startangle=90,
                  colors=['lightblue', 'lightcoral'])
            plt.title('Pause Type Distribution')
    
    def _plot_speech_vs_pause_time(self, metrics: SpeechFlowMetrics):
        """ë°œí™” vs ë©ˆì¶¤ ì‹œê°„ íŒŒì´ ì°¨íŠ¸."""
        import matplotlib.pyplot as plt
        
        plt.subplot(2, 2, 2)
        speech_time = metrics.speech_duration
        pause_time = metrics.pause_duration
        
        if speech_time + pause_time > 0:
            plt.pie([speech_time, pause_time], 
                  labels=['Speech Time', 'Pause Time'],
                  autopct='%1.1f%%',
                  startangle=90,
                  colors=['lightgreen', 'wheat'])
            plt.title('Speech vs Pause Time Distribution')
    
    def _plot_key_metrics_bar(self, metrics: SpeechFlowMetrics):
        """ì£¼ìš” ë©”íŠ¸ë¦­ ë§‰ëŒ€ ê·¸ë˜í”„."""
        import matplotlib.pyplot as plt
        
        plt.subplot(2, 2, 3)
        metrics_names = ['Speech Rate', 'Articulation Rate', 'Pause Frequency', 'Hesitation Score']
        metrics_values = [
            metrics.speech_rate, 
            metrics.articulation_rate, 
            metrics.pause_frequency,
            metrics.hesitation_score * 100
        ]
        
        plt.bar(metrics_names, metrics_values, color=['lightgreen', 'skyblue', 'salmon', 'plum'])
        plt.title('Key Speech Metrics')
        plt.ylabel('Value')
        plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    def _plot_hesitation_gauge(self, metrics: SpeechFlowMetrics):
        """ë§ë”ë“¬ ì ìˆ˜ ê²Œì´ì§€."""
        import matplotlib.pyplot as plt
        
        plt.subplot(2, 2, 4)
        score = metrics.hesitation_score
        color, level = self._get_hesitation_level_color(score)
        
        plt.barh(['Hesitation Level'], [score], color=color)
        plt.xlim(0, 1)
        plt.title(f'Hesitation Score: {score:.2f} ({level})')
        plt.xlabel('Score (0-1)')
    
    def _get_hesitation_level_color(self, score: float) -> Tuple[str, str]:
        """ë§ë”ë“¬ ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒê³¼ ë ˆë²¨ ë°˜í™˜."""
        if score < 0.3:
            return 'green', 'Low'
        elif score < 0.6:
            return 'orange', 'Medium'
        else:
            return 'red', 'High'
    
    def _save_or_show_plot(self, plt, output_path: Optional[str]):
        """ê·¸ë˜í”„ ì €ì¥ ë˜ëŠ” í‘œì‹œ."""
        if output_path:
            plt.savefig(output_path)
            self.logger.info(f"ë¶„ì„ ê²°ê³¼ ì‹œê°í™”ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
        else:
            plt.show()
    
    def save_analysis_results(self, metrics: Union[SpeechFlowMetrics, Dict[str, SpeechFlowMetrics]], 
                            output_path: str) -> None:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥.
        
        Args:
            metrics: ë°œí™” íë¦„ ë©”íŠ¸ë¦­ ë˜ëŠ” í™”ìë³„ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        try:
            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            if isinstance(metrics, dict):
                results = {
                    "speaker_metrics": {
                        speaker: self._metrics_to_dict(m) for speaker, m in metrics.items()
                    }
                }
            else:
                results = {
                    "metrics": self._metrics_to_dict(metrics)
                }
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _metrics_to_dict(self, metrics: SpeechFlowMetrics) -> Dict:
        """SpeechFlowMetrics ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜."""
        return {
            "total_duration": metrics.total_duration,
            "speech_duration": metrics.speech_duration,
            "pause_duration": metrics.pause_duration,
            "silent_pause_count": metrics.silent_pause_count,
            "filled_pause_count": metrics.filled_pause_count,
            "speech_rate": metrics.speech_rate,
            "articulation_rate": metrics.articulation_rate,
            "avg_pause_duration": metrics.avg_pause_duration,
            "pause_frequency": metrics.pause_frequency,
            "pause_to_speech_ratio": metrics.pause_to_speech_ratio,
            "hesitation_score": metrics.hesitation_score
        }
